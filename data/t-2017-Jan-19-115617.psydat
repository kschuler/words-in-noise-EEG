ccopy_reg
_reconstructor
p1
(cpsychopy.data
ExperimentHandler
p2
c__builtin__
object
p3
NtRp4
(dp5
S'originPath'
p6
NsS'dataFileName'
p7
Vdata/t-2017-Jan-19-115617
p8
sS'runtimeInfo'
p9
cpsychopy.info
RunTimeInfo
p10
sS'name'
p11
S'words-in-noise-EEG'
p12
sS'dataNames'
p13
(lp14
S'.maxVal'
p15
aS'.nDown'
p16
aS'.staircase'
p17
aS'.minVal'
p18
aS'.stepType'
p19
aS'.label'
p20
aS'.stepSizes'
p21
aS'.nUp'
p22
aS'.startVal'
p23
aS'.condition'
p24
aS'.thisIndex'
p25
aS'.thisRepN'
p26
aS'.thisN'
p27
aS'.direction'
p28
aS'.stepSize'
p29
aS'.intensity'
p30
aS'actual_onset_time'
p31
aS'actual_offset_time'
p32
aS'intertrial_interval'
p33
aS'prestimulus_period'
p34
aS'stimulus_presentation_window'
p35
aS'poststimulus_waiting_period'
p36
aS'correct_answer'
p37
aS'answer_choice_position'
p38
aS'answer_choice'
p39
aS'is_correct'
p40
aS'RT'
p41
aS'.response'
p42
asS'autoLog'
p43
I01
sS'extraInfo'
p44
(dp45
S'wordlist'
p46
S'list2.yaml'
p47
sS'gender'
p48
S'male'
p49
sS'date-run'
p50
V2017-Jan-19-115617
p51
sS'hand'
p52
S'left'
p53
sS'conditions'
p54
(lp55
S'Auditory'
p56
asS'subject'
p57
Vt
ssS'loopsUnfinished'
p58
(lp59
g1
(cpsychopy.data
MultiStairHandler
p60
g3
NtRp61
(dp62
S'origin'
p63
Nsg6
S'/Volumes/SUPERIOR/KELLY BACKUP/TaskProgramming/words-in-noise-EEG-FINAL/experiment_1_19_17.py'
p64
sS'_exp'
p65
I4629495312
sg11
S''
sS'totalTrials'
p66
I4
sS'runningStaircases'
p67
(lp68
g1
(cpsychopy.data
StairHandler
p69
g3
NtRp70
(dp71
g63
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p72
sS'nDown'
p73
I1
sg65
NsS'reversalIntensities'
p74
(lp75
F3.1697863849222272
asS'stepSizes'
p76
(lp77
I4
asS'nUp'
p78
I3
sS'startVal'
p79
F2
sS'_nextIntensity'
p80
F2
sg43
I01
sS'method'
p81
S'2AFC'
p82
sS'maxVal'
p83
S'None'
p84
sS'stepSizeCurrent'
p85
I4
sS'correctCounter'
p86
I0
sS'nReversals'
p87
NsS'minVal'
p88
F0.050000000000000003
sS'otherData'
p89
(dp90
S'block'
p91
(lp92
I1
aI1
aI1
asS'condition'
p93
(lp94
cnumpy.core.multiarray
scalar
p95
(cnumpy
dtype
p96
(S'S8'
I0
I1
tRp97
(I3
S'|'
NNNI8
I1
I0
tbS'Auditory'
tRp98
ag98
ag98
assS'finished'
p99
I00
sS'stepType'
p100
S'db'
p101
sS'data'
p102
(lp103
I00
aI01
asg93
(dp104
S'maxVal'
p105
g84
sS'nDown'
p106
I1
sS'staircase'
p107
S'baseline'
p108
sS'minVal'
p109
F0.050000000000000003
sS'stepType'
p110
g101
sS'label'
p111
S'easy'
p112
sS'stepSizes'
p113
I4
sS'nUp'
p114
I3
sS'startVal'
p115
F2
sS'condition'
p116
S'Auditory'
p117
ssS'reversalPoints'
p118
(lp119
I1
asg6
S'/Applications/PsychoPy2.app/Contents/Resources/lib/python2.7/psychopy/data.py'
p120
sg11
S''
sg44
NsS'currentDirection'
p121
S'down'
p122
sS'_variableStep'
p123
I00
sS'intensities'
p124
(lp125
F2
aF3.1697863849222272
asS'initialRule'
p126
I0
sS'nTrials'
p127
I20
sS'thisTrialN'
p128
I1
sbag1
(g69
g3
NtRp129
(dp130
g63
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p131
sg73
I1
sg65
Nsg74
(lp132
F1.2619146889603865
asg76
(lp133
I4
asg78
I1
sg79
F2
sg80
F2
sg43
I01
sg81
g82
sg83
S'None'
p134
sg85
I4
sg86
I0
sg87
Nsg88
F0.050000000000000003
sg89
(dp135
g91
(lp136
I1
asg93
(lp137
g98
assg99
I00
sg100
S'db'
p138
sg102
(lp139
I01
aI00
asg93
(dp140
S'maxVal'
p141
g134
sS'nDown'
p142
I1
sS'staircase'
p143
S'baseline'
p144
sS'minVal'
p145
F0.050000000000000003
sS'stepType'
p146
g138
sS'label'
p147
S'hard'
p148
sS'stepSizes'
p149
I4
sS'nUp'
p150
I1
sS'startVal'
p151
F2
sS'condition'
p152
S'Auditory'
p153
ssg118
(lp154
I1
asg6
g120
sg11
S''
sg44
Nsg121
S'up'
p155
sg123
I00
sg124
(lp156
F2
aF1.2619146889603865
asg126
I0
sg127
I20
sg128
I1
sbasS'thisPassRemaining'
p157
(lp158
sS'type'
p159
S'simple'
p160
sg43
I01
sS'currentStaircase'
p161
g129
sg99
I00
sS'staircases'
p162
(lp163
g70
ag129
asg127
I20
sS'conditions'
p164
(lp165
g104
ag140
asg81
S'random'
p166
sg80
F1.2619146889603865
sbasS'saveWideText'
p167
I00
sS'thisEntry'
p168
(dp169
sS'version'
p170
S''
sS'_paramNamesSoFar'
p171
(lp172
sS'entries'
p173
(lp174
(dp175
g21
I4
sg23
F2
sg28
S'start'
p176
sg40
I00
sg32
g95
(g96
(S'f8'
I0
I1
tRp177
(I3
S'<'
NNNI-1
I-1
I0
tbS'\x93\xa7\x8a\x10\xf3\x04\xf8?'
tRp178
sg29
I4
sg50
g51
sg31
g95
(g177
S'333333\xd3?'
tRp179
sg41
F40.334078073501587
sg18
F0.050000000000000003
sg15
g84
sg38
S'right'
p180
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg57
Vt
sg54
g55
sg46
g47
sg27
I0
sg34
I1
sg19
g101
sg52
g53
sg39
Vcold
p181
sg17
g108
sg22
I3
sg26
I1
sg48
g49
sg24
g117
sg30
F2
sg20
g112
sg37
S'code'
p182
sg16
I1
sa(dp183
S'.stepSizes'
p184
I4
sS'.startVal'
p185
F2
sg28
g176
sg40
I01
sg32
g95
(g177
S'\xaa*2\x11\x11\xf1\x02@'
tRp186
sg29
I4
sg50
g51
sg31
g95
(g177
S'UUUUUU\xf5?'
tRp187
sg41
F49.26970100402832
sS'.minVal'
p188
F0.050000000000000003
sS'.maxVal'
p189
g134
sg38
S'left'
p190
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg57
Vt
sg54
g55
sg46
g47
sg27
I1
sg34
I1
sS'.stepType'
p191
g138
sg52
g53
sg39
Vstool
p192
sS'.staircase'
p193
g144
sS'.nUp'
p194
I1
sg26
I1
sg48
g49
sS'.condition'
p195
g153
sg30
F2
sS'.label'
p196
g148
sg37
S'stool'
p197
sS'.nDown'
p198
I1
sa(dp199
S'.stepSizes'
p200
I4
sS'.startVal'
p201
F2
sg28
g155
sg40
I01
sg32
g95
(g177
S'\x88\xcf@\xc6gh\x04@'
tRp202
sg29
I4
sg50
g51
sg31
g95
(g177
S'UUUUUU\xf9?'
tRp203
sg41
F58.349505186080933
sS'.minVal'
p204
F0.050000000000000003
sS'.maxVal'
p205
g84
sg38
S'right'
p206
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg57
Vt
sg54
g55
sg46
g47
sg27
I2
sg34
I1
sS'.stepType'
p207
g101
sg52
g53
sg39
Vtie
p208
sS'.staircase'
p209
g108
sS'.nUp'
p210
I3
sg26
I2
sg48
g49
sS'.condition'
p211
g117
sg30
F3.1697863849222272
sS'.label'
p212
g112
sg37
S'tie'
p213
sS'.nDown'
p214
I1
sa(dp215
S'.stepSizes'
p216
I4
sS'.startVal'
p217
F2
sg28
g122
sg40
I00
sg32
g95
(g177
S'\x11\x8c6N\xa9h\x00@'
tRp218
sg29
I4
sg50
g51
sg31
g95
(g177
S'gfffff\xee?'
tRp219
sg41
S'NA'
p220
sS'.minVal'
p221
F0.050000000000000003
sS'.maxVal'
p222
g134
sg38
g220
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg57
Vt
sg54
g55
sg46
g47
sg27
I3
sg34
I1
sS'.stepType'
p223
g138
sg52
g53
sg39
g220
sS'.staircase'
p224
g144
sS'.nUp'
p225
I1
sg26
I2
sg48
g49
sS'.condition'
p226
g153
sg30
F1.2619146889603865
sS'.label'
p227
g148
sg37
S'mend'
p228
sS'.nDown'
p229
I1
sasS'loops'
p230
(lp231
g61
asS'savePickle'
p232
I00
sb.