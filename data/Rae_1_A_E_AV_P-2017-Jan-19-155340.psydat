ccopy_reg
_reconstructor
p1
(cpsychopy.data
ExperimentHandler
p2
c__builtin__
object
p3
NtRp4
(dp5
S'originPath'
p6
NsS'dataFileName'
p7
Vdata/Rae_1_A_E_AV_P-2017-Jan-19-155340
p8
sS'runtimeInfo'
p9
cpsychopy.info
RunTimeInfo
p10
sS'name'
p11
S'words-in-noise-EEG'
p12
sS'dataNames'
p13
(lp14
S'.maxVal'
p15
aS'.nDown'
p16
aS'.staircase'
p17
aS'.minVal'
p18
aS'.stepType'
p19
aS'.label'
p20
aS'.stepSizes'
p21
aS'.nUp'
p22
aS'.startVal'
p23
aS'.condition'
p24
aS'.thisIndex'
p25
aS'.thisRepN'
p26
aS'.thisN'
p27
aS'.direction'
p28
aS'.stepSize'
p29
aS'.intensity'
p30
aS'actual_onset_time'
p31
aS'actual_offset_time'
p32
aS'intertrial_interval'
p33
aS'prestimulus_period'
p34
aS'stimulus_presentation_window'
p35
aS'poststimulus_waiting_period'
p36
aS'correct_answer'
p37
aS'answer_choice_position'
p38
aS'answer_choice'
p39
aS'is_correct'
p40
aS'RT'
p41
aS'.response'
p42
asS'autoLog'
p43
I01
sS'extraInfo'
p44
(dp45
S'wordlist'
p46
S'list1.yaml'
p47
sS'gender'
p48
S'female'
p49
sS'date-run'
p50
V2017-Jan-19-155340
p51
sS'hand'
p52
S'right'
p53
sS'conditions'
p54
(lp55
S'Auditory'
p56
aS'Environmental'
p57
aS'Visual'
p58
aS'Phoneme'
p59
asS'subject'
p60
VRae_1_A_E_AV_P
p61
ssS'loopsUnfinished'
p62
(lp63
g1
(cpsychopy.data
MultiStairHandler
p64
g3
NtRp65
(dp66
S'origin'
p67
Nsg6
S'/Volumes/SUPERIOR/KELLY BACKUP/TaskProgramming/words-in-noise-EEG-FINAL/experiment_1_19_17.py'
p68
sS'_exp'
p69
I4629499408
sg11
S''
sS'totalTrials'
p70
I20
sS'runningStaircases'
p71
(lp72
g1
(cpsychopy.data
StairHandler
p73
g3
NtRp74
(dp75
g67
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p76
sS'nDown'
p77
I1
sg69
NsS'reversalIntensities'
p78
(lp79
F0.79621434110699441
aF1.2619146889603865
asS'stepSizes'
p80
(lp81
I4
asS'nUp'
p82
I3
sS'startVal'
p83
F2
sS'_nextIntensity'
p84
F0.50237728630191592
sg43
I01
sS'method'
p85
S'2AFC'
p86
sS'maxVal'
p87
S'None'
p88
sS'stepSizeCurrent'
p89
I4
sS'correctCounter'
p90
I-2
sS'nReversals'
p91
NsS'minVal'
p92
F0.050000000000000003
sS'otherData'
p93
(dp94
S'block'
p95
(lp96
I1
aI1
aI1
aI1
aI1
aI5
aI5
aI5
aI5
aI5
asS'condition'
p97
(lp98
cnumpy.core.multiarray
scalar
p99
(cnumpy
dtype
p100
(S'S8'
I0
I1
tRp101
(I3
S'|'
NNNI8
I1
I0
tbS'Auditory'
tRp102
ag102
ag102
ag102
ag102
ag99
(g100
(S'S8'
I0
I1
tRp103
(I3
S'|'
NNNI8
I1
I0
tbS'Auditory'
tRp104
ag104
ag104
ag104
ag104
assS'finished'
p105
I00
sS'stepType'
p106
S'db'
p107
sS'data'
p108
(lp109
I01
aI01
aI00
aI00
aI00
aI01
aI00
aI01
aI00
aI00
asg97
(dp110
S'maxVal'
p111
g88
sS'nDown'
p112
I1
sS'staircase'
p113
S'baseline'
p114
sS'minVal'
p115
F0.050000000000000003
sS'stepType'
p116
g107
sS'label'
p117
S'easy'
p118
sS'stepSizes'
p119
I4
sS'nUp'
p120
I3
sS'startVal'
p121
F2
sS'condition'
p122
S'Auditory'
p123
ssS'reversalPoints'
p124
(lp125
I2
aI5
asg6
S'/Applications/PsychoPy2.app/Contents/Resources/lib/python2.7/psychopy/data.py'
p126
sg11
S''
sg44
NsS'currentDirection'
p127
S'down'
p128
sS'_variableStep'
p129
I00
sS'intensities'
p130
(lp131
F2
aF1.2619146889603865
aF0.79621434110699441
aF1.2619146889603865
aF1.2619146889603865
aF1.2619146889603865
aF0.79621434110699441
aF0.79621434110699441
aF0.50237728630191592
aF0.50237728630191592
asS'initialRule'
p132
I0
sS'nTrials'
p133
I20
sS'thisTrialN'
p134
I9
sbag1
(g73
g3
NtRp135
(dp136
g67
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p137
sg77
I1
sg69
Nsg78
(lp138
F3.1697863849222272
aF2
aF3.1697863849222272
aF2
aF3.1697863849222272
aF0.79621434110699441
aF1.2619146889603865
asg80
(lp139
I4
asg82
I1
sg83
F2
sg84
F0.79621434110699441
sg43
I01
sg85
g86
sg87
S'None'
p140
sg89
I4
sg90
I0
sg91
Nsg92
F0.050000000000000003
sg93
(dp141
g95
(lp142
I1
aI1
aI1
aI1
aI1
aI5
aI5
aI5
aI5
aI5
asg97
(lp143
g102
ag102
ag102
ag102
ag102
ag104
ag104
ag104
ag104
ag104
assg105
I00
sg106
S'db'
p144
sg108
(lp145
I00
aI01
aI00
aI01
aI00
aI01
aI01
aI01
aI00
aI01
asg97
(dp146
S'maxVal'
p147
g140
sS'nDown'
p148
I1
sS'staircase'
p149
S'baseline'
p150
sS'minVal'
p151
F0.050000000000000003
sS'stepType'
p152
g144
sS'label'
p153
S'hard'
p154
sS'stepSizes'
p155
I4
sS'nUp'
p156
I1
sS'startVal'
p157
F2
sS'condition'
p158
S'Auditory'
p159
ssg124
(lp160
I1
aI2
aI3
aI4
aI5
aI8
aI9
asg6
g126
sg11
S''
sg44
Nsg127
g128
sg129
I00
sg130
(lp161
F2
aF3.1697863849222272
aF2
aF3.1697863849222272
aF2
aF3.1697863849222272
aF2
aF1.2619146889603865
aF0.79621434110699441
aF1.2619146889603865
asg132
I0
sg133
I20
sg134
I9
sbasS'thisPassRemaining'
p162
(lp163
sS'type'
p164
S'simple'
p165
sg43
I01
sS'currentStaircase'
p166
g74
sg105
I00
sS'staircases'
p167
(lp168
g74
ag135
asg133
I20
sS'conditions'
p169
(lp170
g110
ag146
asg85
S'random'
p171
sg84
F0.50237728630191592
sbag1
(g64
g3
NtRp172
(dp173
g67
Nsg6
g68
sg69
I4629499408
sg11
S''
sg70
I20
sg71
(lp174
g1
(g73
g3
NtRp175
(dp176
g67
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p177
sg77
I1
sg69
Nsg78
(lp178
F0.79621434110699441
aF1.2619146889603865
aF0.50237728630191592
aF0.79621434110699441
asg80
(lp179
I4
asg82
I3
sg83
F2
sg84
F0.31697863849222263
sg43
I01
sg85
g86
sg87
S'None'
p180
sg89
I4
sg90
I0
sg91
Nsg92
F0.050000000000000003
sg93
(dp181
g95
(lp182
I2
aI2
aI2
aI2
aI2
aI2
aI6
aI6
aI6
aI6
aI6
asg97
(lp183
g99
(g100
(S'S7'
I0
I1
tRp184
(I3
S'|'
NNNI7
I1
I0
tbS'Phoneme'
tRp185
ag185
ag185
ag185
ag185
ag185
ag99
(g100
(S'S7'
I0
I1
tRp186
(I3
S'|'
NNNI7
I1
I0
tbS'Phoneme'
tRp187
ag187
ag187
ag187
ag187
assg105
I00
sg106
S'db'
p188
sg108
(lp189
I01
aI01
aI00
aI01
aI01
aI00
aI00
aI00
aI01
aI01
asg97
(dp190
S'maxVal'
p191
g180
sS'nDown'
p192
I1
sS'staircase'
p193
S'baseline'
p194
sS'minVal'
p195
F0.050000000000000003
sS'stepType'
p196
g188
sS'label'
p197
S'easy'
p198
sS'stepSizes'
p199
I4
sS'nUp'
p200
I3
sS'startVal'
p201
F2
sS'condition'
p202
S'Phoneme'
p203
ssg124
(lp204
I2
aI3
aI7
aI8
asg6
g126
sg11
S''
sg44
Nsg127
g128
sg129
I00
sg130
(lp205
F2
aF1.2619146889603865
aF0.79621434110699441
aF1.2619146889603865
aF0.79621434110699441
aF0.50237728630191592
aF0.50237728630191592
aF0.50237728630191592
aF0.79621434110699441
aF0.50237728630191592
asg132
I0
sg133
I20
sg134
I9
sbag1
(g73
g3
NtRp206
(dp207
g67
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p208
sg77
I1
sg69
Nsg78
(lp209
F1.2619146889603865
aF2
aF0.79621434110699441
aF2
asg80
(lp210
I4
asg82
I1
sg83
F2
sg84
F0.31697863849222263
sg43
I01
sg85
g86
sg87
S'None'
p211
sg89
I4
sg90
I0
sg91
Nsg92
F0.050000000000000003
sg93
(dp212
g95
(lp213
I2
aI2
aI2
aI2
aI6
aI6
aI6
aI6
aI6
asg97
(lp214
g185
ag185
ag185
ag185
ag187
ag187
ag187
ag187
ag187
assg105
I00
sg106
S'db'
p215
sg108
(lp216
I01
aI00
aI01
aI01
aI00
aI00
aI01
aI01
aI01
aI01
asg97
(dp217
S'maxVal'
p218
g211
sS'nDown'
p219
I1
sS'staircase'
p220
S'baseline'
p221
sS'minVal'
p222
F0.050000000000000003
sS'stepType'
p223
g215
sS'label'
p224
S'hard'
p225
sS'stepSizes'
p226
I4
sS'nUp'
p227
I1
sS'startVal'
p228
F2
sS'condition'
p229
S'Phoneme'
p230
ssg124
(lp231
I1
aI2
aI4
aI6
asg6
g126
sg11
S''
sg44
Nsg127
g128
sg129
I00
sg130
(lp232
F2
aF1.2619146889603865
aF2
aF1.2619146889603865
aF0.79621434110699441
aF1.2619146889603865
aF2
aF1.2619146889603865
aF0.79621434110699441
aF0.50237728630191592
asg132
I0
sg133
I20
sg134
I9
sbasg162
(lp233
sg164
g165
sg43
I01
sg166
g206
sg105
I00
sg167
(lp234
g175
ag206
asg133
I20
sg169
(lp235
g190
ag217
asg85
g171
sg84
F0.50237728630191592
sbag1
(g64
g3
NtRp236
(dp237
g67
Nsg6
g68
sg69
I4629499408
sg11
S''
sg70
I20
sg71
(lp238
g1
(g73
g3
NtRp239
(dp240
g67
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p241
sg77
I1
sg69
Nsg78
(lp242
F2.004748934509089
aF2.523829377920773
aF1.5924286822139888
aF2.004748934509089
asg80
(lp243
I2
asg82
I3
sg83
F4
sg84
F1.5924286822139888
sg43
I01
sg85
g86
sg87
S'None'
p244
sg89
I2
sg90
I0
sg91
Nsg92
F0.050000000000000003
sg93
(dp245
g95
(lp246
I3
aI3
aI3
aI3
aI3
aI3
aI7
aI7
aI7
aI7
asg97
(lp247
g99
(g100
(S'S13'
I0
I1
tRp248
(I3
S'|'
NNNI13
I1
I0
tbS'Environmental'
tRp249
ag249
ag249
ag249
ag249
ag249
ag99
(g100
(S'S13'
I0
I1
tRp250
(I3
S'|'
NNNI13
I1
I0
tbS'Environmental'
tRp251
ag251
ag251
ag251
assg105
I00
sg106
S'db'
p252
sg108
(lp253
I01
aI01
aI01
aI00
aI01
aI01
aI00
aI00
aI00
aI01
asg97
(dp254
S'maxVal'
p255
g244
sS'nDown'
p256
I1
sS'staircase'
p257
S'baseline'
p258
sS'minVal'
p259
F0.050000000000000003
sS'stepType'
p260
g252
sS'label'
p261
S'easy'
p262
sS'stepSizes'
p263
I2
sS'nUp'
p264
I3
sS'startVal'
p265
F4
sS'condition'
p266
S'Environmental'
p267
ssg124
(lp268
I3
aI4
aI8
aI9
asg6
g126
sg11
S''
sg44
Nsg127
g128
sg129
I00
sg130
(lp269
F4
aF3.177312938897126
aF2.523829377920773
aF2.004748934509089
aF2.523829377920773
aF2.004748934509089
aF1.5924286822139888
aF1.5924286822139888
aF1.5924286822139888
aF2.004748934509089
asg132
I0
sg133
I20
sg134
I9
sbag1
(g73
g3
NtRp270
(dp271
g67
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p272
sg77
I1
sg69
Nsg78
(lp273
F1.5924286822139888
aF2.523829377920773
aF1.2649110640673515
asg80
(lp274
I2
asg82
I1
sg83
F4
sg84
F1.5924286822139888
sg43
I01
sg85
g86
sg87
S'None'
p275
sg89
I2
sg90
I0
sg91
Nsg92
F0.050000000000000003
sg93
(dp276
g95
(lp277
I3
aI3
aI3
aI3
aI7
aI7
aI7
aI7
aI7
aI7
asg97
(lp278
g249
ag249
ag249
ag249
ag251
ag251
ag251
ag251
ag251
ag251
assg105
I00
sg106
S'db'
p279
sg108
(lp280
I01
aI01
aI01
aI01
aI00
aI00
aI01
aI01
aI01
aI00
asg97
(dp281
S'maxVal'
p282
g275
sS'nDown'
p283
I1
sS'staircase'
p284
S'baseline'
p285
sS'minVal'
p286
F0.050000000000000003
sS'stepType'
p287
g279
sS'label'
p288
S'hard'
p289
sS'stepSizes'
p290
I2
sS'nUp'
p291
I1
sS'startVal'
p292
F4
sS'condition'
p293
S'Environmental'
p294
ssg124
(lp295
I4
aI6
aI9
asg6
g126
sg11
S''
sg44
Nsg127
S'up'
p296
sg129
I00
sg130
(lp297
F4
aF3.177312938897126
aF2.523829377920773
aF2.004748934509089
aF1.5924286822139888
aF2.004748934509089
aF2.523829377920773
aF2.004748934509089
aF1.5924286822139888
aF1.2649110640673515
asg132
I0
sg133
I20
sg134
I9
sbasg162
(lp298
sg164
g165
sg43
I01
sg166
g239
sg105
I00
sg167
(lp299
g239
ag270
asg133
I20
sg169
(lp300
g254
ag281
asg85
g171
sg84
F2.004748934509089
sbag1
(g64
g3
NtRp301
(dp302
g67
Nsg6
g68
sg69
I4629499408
sg11
S''
sg70
I20
sg71
(lp303
g1
(g73
g3
NtRp304
(dp305
g67
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p306
sg77
I1
sg69
Nsg78
(lp307
F1.5848931924611136
asg80
(lp308
I4
asg82
I3
sg83
F1
sg84
F0.099999999999999978
sg43
I01
sg85
g86
sg87
S'None'
p309
sg89
I4
sg90
I0
sg91
Nsg92
F0.050000000000000003
sg93
(dp310
g95
(lp311
I4
aI4
aI4
aI4
aI4
aI8
aI8
aI8
aI8
aI8
asg97
(lp312
g99
(g100
(S'S6'
I0
I1
tRp313
(I3
S'|'
NNNI6
I1
I0
tbS'Visual'
tRp314
ag314
ag314
ag314
ag314
ag99
(g100
(S'S6'
I0
I1
tRp315
(I3
S'|'
NNNI6
I1
I0
tbS'Visual'
tRp316
ag316
ag316
ag316
ag316
assg105
I00
sg106
S'db'
p317
sg108
(lp318
I00
aI01
aI00
aI01
aI01
aI01
aI00
aI00
aI01
aI01
asg97
(dp319
S'maxVal'
p320
g309
sS'nDown'
p321
I1
sS'staircase'
p322
S'baseline'
p323
sS'minVal'
p324
F0.050000000000000003
sS'stepType'
p325
g317
sS'label'
p326
S'easy'
p327
sS'stepSizes'
p328
I4
sS'nUp'
p329
I3
sS'startVal'
p330
F1
sS'condition'
p331
S'Visual'
p332
ssg124
(lp333
I1
asg6
g126
sg11
S''
sg44
Nsg127
g128
sg129
I00
sg130
(lp334
F1
aF1.5848931924611136
aF1
aF1
aF0.63095734448019325
aF0.3981071705534972
aF0.25118864315095796
aF0.25118864315095796
aF0.25118864315095796
aF0.15848931924611132
asg132
I0
sg133
I20
sg134
I9
sbag1
(g73
g3
NtRp335
(dp336
g67
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p337
sg77
I1
sg69
Nsg78
(lp338
F2.5118864315095806
aF0.25118864315095796
aF0.63095734448019325
asg80
(lp339
I4
asg82
I1
sg83
F1
sg84
F0.3981071705534972
sg43
I01
sg85
g86
sg87
S'None'
p340
sg89
I4
sg90
I0
sg91
Nsg92
F0.050000000000000003
sg93
(dp341
g95
(lp342
I4
aI4
aI4
aI4
aI4
aI8
aI8
aI8
aI8
aI8
asg97
(lp343
g314
ag314
ag314
ag314
ag314
ag316
ag316
ag316
ag316
ag316
assg105
I00
sg106
S'db'
p344
sg108
(lp345
I00
aI00
aI01
aI01
aI01
aI01
aI01
aI00
aI00
aI01
asg97
(dp346
S'maxVal'
p347
g340
sS'nDown'
p348
I1
sS'staircase'
p349
S'baseline'
p350
sS'minVal'
p351
F0.050000000000000003
sS'stepType'
p352
g344
sS'label'
p353
S'hard'
p354
sS'stepSizes'
p355
I4
sS'nUp'
p356
I1
sS'startVal'
p357
F1
sS'condition'
p358
S'Visual'
p359
ssg124
(lp360
I2
aI7
aI9
asg6
g126
sg11
S''
sg44
Nsg127
g128
sg129
I00
sg130
(lp361
F1
aF1.5848931924611136
aF2.5118864315095806
aF1.5848931924611136
aF1
aF0.63095734448019325
aF0.3981071705534972
aF0.25118864315095796
aF0.3981071705534972
aF0.63095734448019325
asg132
I0
sg133
I20
sg134
I9
sbasg162
(lp362
sg164
g165
sg43
I01
sg166
g304
sg105
I00
sg167
(lp363
g304
ag335
asg133
I20
sg169
(lp364
g319
ag346
asg85
g171
sg84
F0.15848931924611132
sbag65
ag172
ag236
ag301
ag1
(g64
g3
NtRp365
(dp366
g67
Nsg6
g68
sg69
I4629499408
sg11
S''
sg70
I19
sg71
(lp367
g1
(g73
g3
NtRp368
(dp369
g67
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p370
sg77
I1
sg69
Nsg78
(lp371
F6.3395727698444544
asg80
(lp372
I4
asg82
I3
sg83
F4
sg84
F0.63395727698444526
sg43
I01
sg85
g86
sg87
S'None'
p373
sg89
I4
sg90
I-1
sg91
Nsg92
F0.050000000000000003
sg93
(dp374
g95
(lp375
I1
aI1
aI1
aI1
aI1
aI1
aI1
aI1
aI1
aI1
asg97
(lp376
g99
(g100
(S'S13'
I0
I1
tRp377
(I3
S'|'
NNNI13
I1
I0
tbS'Environmental'
tRp378
ag378
ag378
ag378
ag378
ag378
ag378
ag378
ag378
ag378
assg105
I00
sg106
S'db'
p379
sg108
(lp380
I00
aI01
aI01
aI01
aI00
aI00
aI01
aI01
aI00
asg97
(dp381
S'maxVal'
p382
g373
sS'nDown'
p383
I1
sS'staircase'
p384
S'main'
p385
sS'minVal'
p386
F0.050000000000000003
sS'stepType'
p387
g379
sS'label'
p388
S'easy'
p389
sS'stepSizes'
p390
I4
sS'nUp'
p391
I3
sS'startVal'
p392
F2.004748934509089
sS'condition'
p393
S'Environmental'
p394
ssg124
(lp395
I1
asg6
g126
sg11
S''
sg44
Nsg127
g128
sg129
I00
sg130
(lp396
F4
aF6.3395727698444544
aF4
aF2.523829377920773
aF1.5924286822139888
aF1.5924286822139888
aF1.5924286822139888
aF1.0047545726038318
aF0.63395727698444526
aF0.63395727698444526
asg132
I0
sg133
I100
sg134
I9
sbag1
(g73
g3
NtRp397
(dp398
g67
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis\u000a"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom __future__ import absolute_import\u000a\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle\u000aimport string\u000aimport sys\u000aimport os\u000aimport time\u000aimport copy\u000aimport numpy\u000afrom scipy import optimize, special\u000aimport inspect  # so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000aimport collections\u000a\u000atry:\u000a    # import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl = True\u000aexcept ImportError:\u000a    haveOpenpyxl = False\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom psychopy.contrib.quest import QuestObject  # used for QuestHandler\u000afrom psychopy.contrib.psi import PsiObject  # used for PsiHandler\u000a\u000a_experiments = weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW')  # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 name='',\u000a                 version='',\u000a                 extraInfo=None,\u000a                 runtimeInfo=None,\u000a                 originPath=None,\u000a                 savePickle=True,\u000a                 saveWideText=True,\u000a                 dataFileName='',\u000a                 autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at\u000a                runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless\u000a                .abort() had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops = []\u000a        self.loopsUnfinished = []\u000a        self.name = name\u000a        self.version = version\u000a        self.runtimeInfo = runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo = extraInfo\u000a        self.originPath = originPath\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a        self.dataFileName = dataFileName\u000a        self.thisEntry = {}\u000a        self.entries = []  # chronological list of entries\u000a        self._paramNamesSoFar = []\u000a        self.dataNames = []  # names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName'\u000a                            ' parameter. No data will be saved in the event '\u000a                            'of a crash')\u000a        else:\u000a            # fail now if we fail at all!\u000a            checkValidFilePath(dataFileName, makeValid=True)\u000a\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug(\u000a                    'Saving data for %s ExperimentHandler' % self.name)\u000a            if self.savePickle == True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText == True:\u000a                self.saveAsWideText(self.dataFileName + '.csv', delim=',')\u000a\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler`\u000a        or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        # keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names = copy.deepcopy(self._paramNamesSoFar)\u000a        # get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a\u000a    def _getExtraInfo(self):\u000a        """Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names = []\u000a            vals = []\u000a        else:\u000a            names = self.extraInfo.keys()\u000a            vals = self.extraInfo.values()\u000a        return names, vals\u000a\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial\u000a        of a particular loop. Does not return data inputs from the subject,\u000a        only info relating to the trial execution.\u000a        """\u000a        names = []\u000a        vals = []\u000a        name = loop.name\u000a        # standard attributes\u000a        for attr in ('thisRepN', 'thisTrialN', 'thisN', 'thisIndex',\u000a                     'stepSizeCurrent'):\u000a            if hasattr(loop, attr):\u000a                attrName = name + '.' + attr.replace('Current', '')\u000a                # append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop, attr))\u000a        # method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial, 'items'):\u000a                # is a TrialList object or a simple dict\u000a                for attr, val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a        # single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name + '.intensity')\u000a            if len(loop.intensities) > 0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            # add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            # end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        # could just copy() every value, but not always needed, so check:\u000a        try:\u000a            hash(value)\u000a        except TypeError:\u000a            # unhashable type (list, dict, ...) == mutable, so need a copy()\u000a            value = copy.deepcopy(value)\u000a        self.thisEntry[name] = value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further addData() calls correspond\u000a        to the next trial.\u000a        """\u000a        this = self.thisEntry\u000a        # fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name] = vals[n]\u000a        # add the extraInfo dict to the data\u000a        if type(self.extraInfo) == dict:\u000a            this.update(self.extraInfo)\u000a        self.entries.append(this)\u000a        self.thisEntry = {}\u000a\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=False,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing\u000a        the attributes and data for a single trial. Suitable for analysis\u000a        in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of\u000a        an existing file. Otherwise, if the file exists already it will\u000a        be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row,\u000a        which can be handy if you want to append data to an existing file\u000a        of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        # names from the extraInfo dictionary\u000a        names.extend(self._getExtraInfo()[0])\u000a        # write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' % (heading, delim))\u000a            f.write('\u005cn')\u000a        # write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    ename = unicode(entry[name])\u000a                    if ',' in ename or '\u005cn' in ename:\u000a                        fmt = u'"%s"%s'\u000a                    else:\u000a                        fmt = u'%s%s'\u000a                    f.write(fmt % (entry[name], delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        if f != sys.stdout:\u000a            f.close()\u000a        logging.info('saved data to %r' % f.name)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle and self.saveWideText\u000a        # for later use:\u000a        # We are going to set both to False before saving,\u000a        # so PsychoPy won't try to save again after loading the pickled\u000a        # .psydat file from disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle and\u000a        # self.saveWideText is restored.\u000a        #\u000a        # See\u000a        # https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        savePickle = self.savePickle\u000a        saveWideText = self.saveWideText\u000a\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a        self.saveWideText = saveWideText\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data\u000a        (even in the event of a crash if possible). So if you quit your\u000a        script early you may want to tell the Handler not to save out\u000a        the data files for this run. This is the method that allows you\u000a        to do that.\u000a        """\u000a        self.savePickle = False\u000a        self.saveWideText = False\u000a\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a\u000a    def __getattribute__(self, name):\u000a        try:  # to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                msg = "TrialType has no attribute (or key) \u005c'%s\u005c'"\u000a                raise AttributeError(msg % name)\u000a\u000a\u000aclass _BaseTrialHandler(object):\u000a\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        # need to use a weakref to avoid creating a circular reference that\u000a        # prevents effective object deletion\u000a        expId = id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a        # origin will have been stored by the exp so don't store again:\u000a        self.origin = None\u000a\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to,\u000a        if any. Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        # remove ourself from the list of unfinished loops in the experiment\u000a        exp = self.getExp()\u000a        if exp != None:\u000a            exp.loopEnded(self)\u000a        # and halt the loop\u000a        raise StopIteration\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a\u000a        pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed.'\u000a                             ' Nothing saved')\u000a            return -1\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self, fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a        :Parameters:\u000a\u000a        fileName:\u000a            will have .tsv appended and can include path info.\u000a\u000a        stimOut:\u000a            the stimulus attributes to be output. To use this you need to\u000a            use a list of dictionaries and give here the names of dictionary\u000a            keys that you want as strings\u000a\u000a        dataOut:\u000a            a list of strings specifying the dataType and the analysis to\u000a            be performed,in the form `dataType_analysis`. The data can be\u000a            any of the types that you added using trialHandler.data.add()\u000a            and the analysis can be either 'raw' or most things in the\u000a            numpy library, including; 'mean','std','median','max','min'...\u000a            The default values will output the raw, mean and std of all\u000a            datatypes found\u000a\u000a        delim:\u000a            allows the user to use a delimiter other than tab\u000a            ("," is popular with file extension ".csv")\u000a\u000a        matrixOnly:\u000a            outputs the data with no header row or extraInfo attached\u000a\u000a        appendFile:\u000a            will add this output to the end of the specified file if\u000a            it already exists\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials'\u000a                             ' completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                # surround in quotes to prevent effect of delimiter\u000a                if delim in unicode(entry):\u000a                    f.write(u'"%s"' % unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN < (len(line) - 1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")  # add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n', 'all_mean', 'all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file.\u000a        So you could have a single file named after your experiment and\u000a        then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for\u000a        repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output.\u000a                To use this you need to have provided a list of dictionaries\u000a                specifying to trialList parameter of the TrialHandler and\u000a                give here the names of strings specifying entries in that\u000a                dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data\u000a                can be any of the types that you added using\u000a                trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give\u000a                a column of max reaction times across the trials assuming\u000a                that `rt` values have been stored. The default values will\u000a                output the raw, mean and std of all datatypes found.\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no '\u000a                             'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # NB this was based on the limited documentation (1 page wiki) for\u000a        # openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in'\u000a                              ' Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a                                            dataOut=dataOut,\u000a                                            matrixOnly=matrixOnly)\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()  # create new workbook\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry is None:\u000a                    entry = ''\u000a                try:\u000a                    # if it can convert to a number (from numpy) then do it\u000a                    val = float(entry)\u000a                except Exception:\u000a                    val = unicode(entry)\u000a                _cell = _getExcelCellName(col=colN, row=lineN)\u000a                ws.cell(_cell).value = val\u000a\u000a        ew.save(filename=fileName)\u000a\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this\u000a        data file and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used\u000a        otherwise the calling script is the originPath (fine from a\u000a        standard python script).\u000a        """\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        if originPath == -1:\u000a            return -1, None  # the user wants to avoid storing this\u000a        elif originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(\u000a                    inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" % originPath)\u000a            except Exception:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using "\u000a                                  "inspect.getouterframes")\u000a                return '', ''\u000a        if os.path.isfile(originPath):  # do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin = None\u000a        return originPath, origin\u000a\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom'\u000a                fully randomises the trials across repeats as well,\u000a                which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually\u000a                describes the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the\u000a                script / experiment file path. The psydat file format will\u000a                store a copy of the experiment if possible. If\u000a                `originPath==None` is provided here then the TrialHandler\u000a                will still store a copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes != None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # this is a bool; all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ['random', 'sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif len(str(getattr(self, thisAttrib))) > 20 and not verbose:\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically when\u000a        the TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps, 1)  # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(\u000a                randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self, inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        # make sure its an array of objects (can be strings etc)\u000a        inputArray = numpy.asarray(inputArray, 'O')\u000a        # get some simple variables for later\u000a        dims = inputArray.shape\u000a        dimsProd = numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        # this creates space for an array of any objects\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')\u000a\u000a        # for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            # NB this means modulus in python\u000a            thisDimVals = numpy.arange(dimsProd) / prevDimsProd % dims[thisDim]\u000a            listOfLists.append(thisDimVals)\u000a\u000a        # convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:, n]))\u000a        return (numpy.reshape(arrayOfTuples, dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisTrialN == len(self.trialList):\u000a            # start a new repetition\u000a            self.thisTrialN = 0\u000a            self.thisRepN += 1\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.thisIndex = self.sequenceIndices[\u000a                self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran', 1)\u000a            self.data.add('order', self.thisN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future,\u000a        without advancing the trials. A negative n returns a previous (past)\u000a        trial. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        return self.getFutureTrial(-abs(n))\u000a\u000a    def _createOutputArray(self, stimOut, dataOut, delim=None,\u000a                           matrixOnly=False):\u000a        """Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if (stimOut == [] and\u000a                len(self.trialList) and\u000a                hasattr(self.trialList[0], 'keys')):\u000a            stimOut = self.trialList[0].keys()\u000a            # these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines = []\u000a        # parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut)\u000a        if not matrixOnly:\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # write a header line\u000a            for heading in stimOut + dataHead:\u000a                if heading == 'ran_sum':\u000a                    heading = 'n'\u000a                elif heading == 'order_raw':\u000a                    heading = 'order'\u000a                thisLine.append(heading)\u000a\u000a        # loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine = []\u000a            lines.append(thisLine)\u000a            # first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            # then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                # make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData, 'tolist'):  # is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    # for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion = strVersion.replace('None', '')\u000a                elif tmpData in [None, 'None']:\u000a                    strVersion = ''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion == '()':\u000a                    # 'no data' in masked array should show as "--"\u000a                    strVersion = "--"\u000a                # handle list of values (e.g. rt_raw )\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    strVersion = strVersion[1:-1]  # skip first and last chars\u000a                # handle lists of lists (e.g. raw of multiple key presses)\u000a                if (len(strVersion) and\u000a                        strVersion[0] in '[(' and\u000a                        strVersion[-1] in '])'):\u000a                    tup = eval(strVersion)  # convert back to a tuple\u000a                    for entry in tup:\u000a                        # contents of each entry is a list or tuple so keep in\u000a                        # quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        # add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            # give a single line of space and then a heading\u000a            lines.append(['extraInfo'])\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key, value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a        dataHead = []  # will store list of data headers\u000a        dataAnal = dict([])  # will store data that has been analyzed\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to be full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend(\u000a                    [key + "_" + analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # will fail if we try to take mean of a string for example\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010 (because\u000a                        # of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be\u000a        set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended\u000a                if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        # this is wide format, so we want fixed information\u000a        # (e.g. subject ID, date, etc) repeated every line if it exists:\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns=header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a\u000a                # create a dictionary representing each trial:\u000a                nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of vars in header:\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    tti = trialTypeIndex\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                    elif self.extraInfo != None and prmName in self.extraInfo:\u000a                        nextEntry[prmName] = self.extraInfo[prmName]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        if prmName == "TrialNumber":\u000a                            nextEntry[prmName] = trialCount\u000a                        else:\u000a                            nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a            # write the header row:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + prmName + delim\u000a            # remove the final orphaned tab character\u000a            f.write(nextLine[:-1] + '\u005cn')\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for prmName in header:\u000a                nextLine = nextLine + unicode(trial[prmName]) + delim\u000a            # remove the final orphaned tab character\u000a            nextLine = nextLine[:-1]\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a        # Converts numbers to numeric, such as float64, boolean to bool.\u000a        # Otherwise they all are "object" type, i.e. strings\u000a        df = df.convert_objects()\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandler2(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the\u000a    TrialHandler object that saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order\u000a                they appear in the list. 'random' will result in a shuffle\u000a                of the conditions on each repeat, but all conditions occur\u000a                once before the second repeat etc. 'fullRandom' fully\u000a                randomises the trials across repeats as well, which means\u000a                you could potentially run all trials of one condition\u000a                before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage.\u000a                e.g. ['corr','rt','resp']. If not provided then these\u000a                will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to\u000a                use the same pattern of trials, by seeding its startpoint.\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was\u000a                created. If `OriginPath==-1` then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:  # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a            self.columns = []\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList, self.columns = importConditions(trialList, True)\u000a        else:\u000a            self.trialList = trialList\u000a            self.columns = trialList[0].keys()\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps * len(self.trialList)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.remainingIndices = []\u000a        self.prevIndices = []\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = None  # index of current trial in the conditions list\u000a        self.thisTrial = {}\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        self._rng = numpy.random.RandomState(seed=seed)\u000a\u000a        # store a list of dicts, convert to pandas.DataFrame on access\u000a        self._data = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string\u000a        """\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object\u000a        """\u000a        strRepres = 'psychopy.data.{}(\u005cn'.format(self.__class__.__name__)\u000a        attribs = dir(self)\u000a        # data first, then all others\u000a        try:\u000a            data = self.data\u000a        except Exception:\u000a            strRepres += '\u005ct(no data)\u005cn'\u000a        else:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres += str(data) + '\u005cn'\u000a        for thisAttrib in attribs:\u000a            # can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self, thisAttrib))):\u000a                # this is a method\u000a                continue\u000a            elif thisAttrib[0] == '_':\u000a                # the attrib is private\u000a                continue\u000a            elif thisAttrib == 'data':\u000a                # we handled this first\u000a                continue\u000a            elif (len(str(getattr(self, thisAttrib))) > 20 and\u000a                    not verbose):\u000a                # just give type of LONG public attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(type(getattr(self, thisAttrib))) + '\u005cn'\u000a            else:\u000a                # give the complete contents of attribute\u000a                strRepres += str('\u005ct' + thisAttrib + '=')\u000a                strRepres += str(getattr(self, thisAttrib)) + '\u005cn'\u000a        strRepres += ')'\u000a        return strRepres\u000a\u000a    @property\u000a    def data(self):\u000a        """Returns a pandas.DataFrame of the trial data so far\u000a        Read only attribute - you can't directly modify TrialHandler.data\u000a\u000a        Note that data are stored internally as a list of dictionaries,\u000a        one per trial. These are converted to a DataFrame on access.\u000a        """\u000a        return DataFrame(self._data)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a        if self.thisIndex is not None:\u000a            self.prevIndices.append(self.thisIndex)\u000a\u000a        # thisRepN has exceeded nReps\u000a        if self.remainingIndices == []:\u000a            # we've just started, or just starting a new repeat\u000a            sequence = range(len(self.trialList))\u000a            if (self.method == 'fullRandom' and\u000a                    self.thisN < (self.nReps * len(self.trialList))):\u000a                # we've only just started on a fullRandom sequence\u000a                sequence *= self.nReps\u000a                self._rng.shuffle(sequence)\u000a                self.remainingIndices = sequence\u000a            elif (self.method in ('sequential', 'random') and\u000a                    self.thisRepN < self.nReps):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a                if self.method == 'random':\u000a                    self._rng.shuffle(sequence)  # shuffle in-place\u000a                self.remainingIndices = sequence\u000a            else:\u000a                # we've finished\u000a                self.finished = True\u000a                self._terminate()  # raises Stop (code won't go beyond here)\u000a\u000a        # fetch the trial info\u000a        if len(self.trialList) == 0:\u000a            self.thisIndex = 0\u000a            self.thisTrial = {}\u000a        else:\u000a            self.thisIndex = self.remainingIndices.pop()\u000a            # if None then use empty dict\u000a            thisTrial = self.trialList[self.thisIndex] or {}\u000a            self.thisTrial = copy.copy(thisTrial)\u000a        # for fullRandom check how many times this has come up before\u000a        if self.method == 'fullRandom':\u000a            self.thisRepN = self.prevIndices.count(self.thisIndex)\u000a\u000a        # update data structure with new info\u000a        self._data.append(self.thisTrial)  # update the data list of dicts\u000a        self.addData('thisN', self.thisN)\u000a        self.addData('thisTrialN', self.thisTrialN)\u000a        self.addData('thisRepN', self.thisRepN)\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without\u000a        advancing the trials. Returns 'None' if attempting to go beyond\u000a        the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative\u000a        # offsets:\u000a        if n > self.nRemaining or self.thisN + n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex = seqs[self.thisN + n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously.\u000a        Useful for comparisons in n-back tasks. Returns 'None' if trying\u000a        to access a trial prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim=None,\u000a                       matrixOnly=False,\u000a                       appendFile=True,\u000a                       encoding='utf-8',\u000a                       fileCollisionMethod='rename'):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order. Also, return a pandas\u000a        DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID': 'Joan Smith',\u000a                                        'Group': 'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no '\u000a                         'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # defer to pandas for actual data output. We're fetching a string\u000a        # repr and then writeing to file ourselves\u000a        # Include header line if not matrixOnly\u000a        datStr = self.data.to_csv(sep=delim,\u000a                                  columns=self.columns,  # sets the order\u000a                                  header=(not matrixOnly),\u000a                                  index=False)\u000a        f.write(datStr)\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a    def addData(self, thisType, value):\u000a        """Add a piece of data to the current trial\u000a        """\u000a        # store in the columns list to help ordering later\u000a        if thisType not in self.columns:\u000a            self.columns.append(thisType)\u000a        # save the actual value in a data dict\u000a        self.thisTrial[thisType] = value\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000aclass TrialHandlerExt(TrialHandler):\u000a    """A class for handling trial sequences in a *non-counterbalanced design*\u000a    (i.e. *oddball paradigms*). Its functions are a superset of the\u000a    class TrialHandler, and as such, can also be used for normal trial\u000a    handling.\u000a\u000a    TrialHandlerExt has the same function names for data storage facilities.\u000a\u000a    To use non-counterbalanced designs, all TrialType dict entries in the\u000a    trial list must have a key called "weight". For example, if you want\u000a    trial types A, B, C, and D to have 10, 5, 3, and 2 repetitions per\u000a    block, then the trialList can look like:\u000a\u000a    [{Name:'A', ..., weight:10},\u000a     {Name:'B', ..., weight:5},\u000a     {Name:'C', ..., weight:3},\u000a     {Name:'D', ..., weight:2}]\u000a\u000a    For experimenters using an excel or csv file for trial list, a column\u000a    called weight is appropriate for this purpose.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom).\u000a    Calls will raise a StopIteration error when all trials are exhausted.\u000a\u000a    *Authored by Suddha Sourav at BPN, Uni Hamburg - heavily borrowing\u000a    from the TrialHandler class*\u000a    """\u000a\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries\u000a                specifying conditions. This can be imported from an\u000a                excel / csv file using :func:`~psychopy.data.importConditions`\u000a                For non-counterbalanced designs, each dict entry in\u000a                trialList must have a key called weight!\u000a\u000a            nReps: number of repeats for all conditions. When using a\u000a                non-counterbalanced design, nReps is analogous to the number\u000a                of blocks.\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                When the weights are not specified:\u000a                'sequential' presents the conditions in the order they appear\u000a                in the list. 'random' will result in a shuffle of the\u000a                conditions on each  repeat, but all conditions occur once\u000a                before the second repeat etc. 'fullRandom' fully randomises\u000a                the trials across repeats as well, which means you could\u000a                potentially run all trials of one condition before any trial\u000a                of another.\u000a\u000a                In the presence of weights:\u000a                'sequential' presents each trial type the number of times\u000a                specified by its weight, before moving on to the next type.\u000a                'random' randomizes the presentation order within block.\u000a                'fulLRandom' shuffles trial order across weights an nRep,\u000a                that is, a full shuffling.\u000a\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g.\u000a                ['corr','rt','resp']. If not provided then these will be\u000a                created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes\u000a                the experiment and subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator\u000a                to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script /\u000a                experiment file path. The psydat file format will store a\u000a                copy of the experiment if possible. If `originPath==None`\u000a                is provided here then the TrialHandler will still store a\u000a                copy of the script where it was created. If `OriginPath==-1`\u000a                then nothing will be stored.\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type\u000a                stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original\u000a                conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current\u000a                trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that\u000a                created the handler\u000a\u000a            .trialWeights - None if all weights are not specified. If all\u000a                weights are specified, then a list containing the weights\u000a                of the trial types.\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in (None, []):\u000a            # user wants an empty trialList\u000a            # which corresponds to a list with a single empty entry\u000a            self.trialList = [None]\u000a        # user has hopefully specified a filename\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList):\u000a            # import conditions from that file\u000a            self.trialList = importConditions(trialList)\u000a        else:\u000a            self.trialList = trialList\u000a        # convert any entry in the TrialList into a TrialType object (with\u000a        # obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry) == dict:\u000a                self.trialList[n] = TrialType(entry)\u000a        self.nReps = nReps\u000a        # Add Su\u000a        if not trialList or not all('weight' in d for d in trialList):\u000a            self.trialWeights = None\u000a            self.nTotal = self.nReps * len(self.trialList)\u000a        else:\u000a            self.trialWeights = [d['weight'] for d in trialList]\u000a            self.nTotal = self.nReps * sum(self.trialWeights)\u000a        self.nRemaining = self.nTotal  # subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0  # records which repetition or pass we are on\u000a        self.thisTrialN = -1  # records trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0  # index of current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished = False\u000a        self.extraInfo = extraInfo\u000a        self.seed = seed\u000a        # create dataHandler\u000a        if self.trialWeights is None:\u000a            self.data = DataHandler(trials=self)\u000a        else:\u000a            self.data = DataHandler(trials=self,\u000a                                    dataShape=[sum(self.trialWeights), nReps])\u000a        if dataTypes is not None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask = False  # bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        # generate stimulus sequence\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            self.sequenceIndices = self._createSequence()\u000a        else:\u000a            self.sequenceIndices = []\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _createSequence(self):\u000a        """Pre-generates the sequence of trial presentations (for\u000a        non-adaptive methods). This is called automatically when the\u000a        TrialHandler is initialised so doesn't need an explicit call\u000a        from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        Example: random, with 3 trialtypes, where the weights of\u000a        conditions 0,1, and 2 are 3,2, and 1 respectively,\u000a        and a rep value of 5, might return:\u000a            [[0 1 2 0 1]\u000a             [1 0 1 1 1]\u000a             [0 2 0 0 0]\u000a             [0 0 0 1 0]\u000a             [2 0 1 0 2]\u000a             [1 1 0 2 0]]\u000a\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 0, 0, 2, 1,   1, 0, 2, 0, 0, 1, ...\u000a            ... 0, 2, 0  *stopIteration*\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy,\u000a        and specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        repeat = numpy.repeat\u000a        reshape = numpy.reshape\u000a        if self.method == 'random':\u000a            seqIndices = []\u000a            seed = self.seed\u000a            for thisRep in range(self.nReps):\u000a                if self.trialWeights is None:\u000a                    idx = indices.flat\u000a                else:\u000a                    idx = repeat(indices, self.trialWeights)\u000a                thisRepSeq = shuffleArray(idx, seed=seed).tolist()\u000a                seed = None  # so that we only seed the first pass through!\u000a                seqIndices.append(thisRepSeq)\u000a            seqIndices = numpy.transpose(seqIndices)\u000a        elif self.method == 'sequential':\u000a            if self.trialWeights is None:\u000a                seqIndices = repeat(indices, self.nReps, 1)\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                seqIndices = repeat(_base, self.nReps, 1)\u000a        elif self.method == 'fullRandom':\u000a            if self.trialWeights is None:\u000a                # indices * nReps, flatten, shuffle, unflatten;\u000a                # only use seed once\u000a                sequential = repeat(indices, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (len(indices), self.nReps))\u000a            else:\u000a                _base = repeat(indices, self.trialWeights, 0)\u000a                sequential = repeat(_base, self.nReps, 1)\u000a                randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a                seqIndices = reshape(randomFlat,\u000a                                     (sum(self.trialWeights), self.nReps))\u000a\u000a        if self.autoLog:\u000a            # Change\u000a            msg = 'Created sequence: %s, trialTypes=%d, nReps=%d, seed=%s'\u000a            vals = (self.method, len(indices), self.nReps, str(self.seed))\u000a            logging.exp(msg % vals)\u000a        return seqIndices\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        # update pointer for next trials\u000a        self.thisTrialN += 1  # number of trial this pass\u000a        self.thisN += 1  # number of trial in total\u000a        self.nRemaining -= 1\u000a\u000a        if self.trialWeights is None:\u000a            if self.thisTrialN == len(self.trialList):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a        else:\u000a            if self.thisTrialN == sum(self.trialWeights):\u000a                # start a new repetition\u000a                self.thisTrialN = 0\u000a                self.thisRepN += 1\u000a\u000a        if self.thisRepN >= self.nReps:\u000a            # all reps complete\u000a            self.thisTrial = []\u000a            self.finished = True\u000a\u000a        if self.finished == True:\u000a            self._terminate()\u000a\u000a        # fetch the trial info\u000a        if self.method in ('random', 'sequential', 'fullRandom'):\u000a            if self.trialWeights is None:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a                self.data.add('ran', 1)\u000a                self.data.add('order', self.thisN)\u000a            else:\u000a                idx = self.sequenceIndices[self.thisTrialN]\u000a                self.thisIndex = idx[self.thisRepN]\u000a                self.thisTrial = self.trialList[self.thisIndex]\u000a\u000a                self.data.add('ran', 1,\u000a                              position=self.getNextTrialPosInDataHandler())\u000a                # The last call already adds a ran to this trial, so get the\u000a                # current pos now\u000a                self.data.add('order', self.thisN,\u000a                              position=self.getCurrentTrialPosInDataHandler())\u000a\u000a        if self.autoLog:\u000a            msg = 'New trial (rep=%i, index=%i): %s'\u000a            vals = (self.thisRepN, self.thisTrialN, self.thisTrial)\u000a            logging.exp(msg % vals, obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getCurrentTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is simply\u000a        # [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex]) - 1\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a number\u000a            # of times. If we had a sequential array, then the rows in\u000a            # DataHandler for that trialIndex would be from\u000a            # sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            # if we haven't begun the experiment yet, then the last row\u000a            # of the first column is used as the current position,\u000a            # emulating what TrialHandler does. The following two lines\u000a            # also prevents calculating garbage position values in case\u000a            # the first row has a null weight\u000a            if self.thisN < 0:\u000a                return [0, -1]\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + (nThisTrialPresented - 1) % _tw\u000a            dataColThisTrial = int((nThisTrialPresented - 1) / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def getNextTrialPosInDataHandler(self):\u000a        # if there's no trial weights, then the current position is\u000a        # simply [trialIndex, nRepetition]\u000a        if self.trialWeights is None:\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            position = [self.trials.thisIndex, repN]\u000a        else:\u000a            # if there are trial weights, the situation is slightly more\u000a            # involved, because the same index can be repeated for a\u000a            # number of times. If we had a sequential array, then the\u000a            # rows in DataHandler for that trialIndex would\u000a            # be from sum(trialWeights[begin:trialIndex]) to\u000a            # sum(trialWeights[begin:trialIndex+1]).\u000a\u000a            firstRowIndex = sum(self.trialWeights[:self.thisIndex])\u000a            lastRowIndex = sum(self.trialWeights[:self.thisIndex + 1])\u000a\u000a            # get the number of the trial presented by summing in ran for the\u000a            # rows above and all columns\u000a            nThisTrialPresented = numpy.sum(\u000a                self.data['ran'][firstRowIndex:lastRowIndex, :])\u000a\u000a            _tw = self.trialWeights[self.thisIndex]\u000a            dataRowThisTrial = firstRowIndex + nThisTrialPresented % _tw\u000a            dataColThisTrial = int(nThisTrialPresented / _tw)\u000a\u000a            position = [dataRowThisTrial, dataColThisTrial]\u000a\u000a        return position\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a\u000a        if self.trialWeights is None:\u000a            pos = None\u000a        else:\u000a            pos = self.getCurrentTrialPosInDataHandler()\u000a        self.data.add(thisType, value, position=pos)\u000a        # change this!\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too:\u000a            self.getExp().addData(thisType, value)\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header\u000a        line and adds the stimOut columns\u000a        """\u000a\u000a        if self.trialWeights is not None:\u000a            # remember to use other array instead of self.data\u000a            _vals = numpy.arange(len(self.trialList))\u000a            idx_data = numpy.repeat(_vals, self.trialWeights)\u000a\u000a        # list of data headers\u000a        dataHead = []\u000a        # will store data that has been analyzed\u000a        dataAnal = dict([])\u000a        if type(dataOut) == str:\u000a            # don't do list convert or we get a list of letters\u000a            dataOut = [dataOut]\u000a        elif type(dataOut) != list:\u000a            dataOut = list(dataOut)\u000a\u000a        # expand any 'all' dataTypes to the full list of available dataTypes\u000a        allDataTypes = self.data.keys()\u000a        # treat these separately later\u000a        allDataTypes.remove('ran')\u000a        # ready to go through standard data types\u000a        dataOutNew = []\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                # n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue  # no need to do more with this one\u000a            # then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                keyType = [key + "_" + analType for key in allDataTypes]\u000a                dataOutNew.extend(keyType)\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut = dataOutNew\u000a        # sort so that all datatypes come together, rather than all analtypes\u000a        dataOut.sort()\u000a\u000a        # do the various analyses, keeping track of fails (e.g. mean of a\u000a        # string)\u000a        dataOutInvalid = []\u000a        # add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:\u000a            # move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0, 'ran_sum')\u000a        if 'order_raw' in dataOut:\u000a            # move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        # do the necessary analysis on the data\u000a        for thisDataOutN, thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                # that analysis can't be done\u000a                dataOutInvalid.append(thisDataOut)\u000a                continue\u000a\u000a            if self.trialWeights is None:\u000a                thisData = self.data[dataType]\u000a            else:\u000a                resizedData = numpy.ma.masked_array(\u000a                    numpy.zeros((len(self.trialList),\u000a                                 max(self.trialWeights) * self.nReps)),\u000a                    numpy.ones((len(self.trialList),\u000a                                max(self.trialWeights) * self.nReps),\u000a                               dtype=bool))\u000a                for curTrialIndex in range(len(self.trialList)):\u000a                    thisDataChunk = self.data[dataType][\u000a                        idx_data == curTrialIndex, :]\u000a                    padWidth = (max(self.trialWeights) * self.nReps -\u000a                                numpy.prod(thisDataChunk.shape))\u000a                    thisDataChunkRowPadded = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().data,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, 0))\u000a                    thisDataChunkRowPaddedMask = numpy.pad(\u000a                        thisDataChunk.transpose().flatten().mask,\u000a                        (0, padWidth), mode='constant',\u000a                        constant_values=(0, True))\u000a\u000a                    thisDataChunkRow = numpy.ma.masked_array(\u000a                        thisDataChunkRowPadded,\u000a                        mask=thisDataChunkRowPaddedMask)\u000a                    resizedData[curTrialIndex, :] = thisDataChunkRow\u000a\u000a                thisData = resizedData\u000a\u000a            # set the header\u000a            dataHead.append(dataType + '_' + analType)\u000a            # analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:\u000a                    # this will fail if we try to take mean of a string\u000a                    if analType == 'std':\u000a                        thisAnal = numpy.std(thisData, axis=1, ddof=0)\u000a                        # normalise by N-1 instead. This should work by\u000a                        # setting ddof=1 but doesn't as of 08/2010\u000a                        # (because of using a masked array?)\u000a                        N = thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal *= 0  # prevent a divide-by-zero error\u000a                        else:\u000a                            sqrt = numpy.sqrt\u000a                            thisAnal = thisAnal * sqrt(N) / sqrt(N - 1)\u000a                    else:\u000a                        thisAnal = eval("numpy.%s(thisData,1)" % analType)\u000a                except Exception:\u000a                    # that analysis doesn't work\u000a                    dataHead.remove(dataType + '_' + analType)\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue  # to next analysis\u000a            elif analType == 'raw':\u000a                thisAnal = thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            # add extra cols to header if necess\u000a            if len(thisAnal.shape) > 1:\u000a                for n in range(thisAnal.shape[1] - 1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut] = thisAnal\u000a\u000a        # remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self, fileName,\u000a                       delim='\u005ct',\u000a                       matrixOnly=False,\u000a                       appendFile=True):\u000a        """Write a text file with the session, stimulus, and data values\u000a        from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarizing is done (such as collapsing to produce mean and\u000a           standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and\u000a        various other analysis programs, means that some information must\u000a        be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each\u000a        entry in there occurs in every row. In builder, this will include\u000a        any entries in the 'Experiment info' field of the\u000a        'Experiment settings' dialog. In Coder, this information can be set\u000a        using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith',\u000a                                        'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if\u000a                the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default\u000a                tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if\u000a                it already exists.\u000a\u000a        """\u000a        if self.thisTrialN < 1 and self.thisRepN < 1:\u000a            # if both are < 1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials'\u000a                         ' completed. Nothing saved')\u000a            return -1\u000a\u000a        # create the file or send to stdout\u000a        if appendFile:\u000a            writeFormat = 'a'\u000a        else:\u000a            writeFormat = 'w'  # will overwrite a file\u000a        if fileName == 'stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ('.dlm', '.DLM', '.tsv', '.TSV',\u000a                               '.txt', '.TXT', '.csv', '.CSV'):\u000a            f = codecs.open(fileName, writeFormat, encoding="utf-8")\u000a        else:\u000a            if delim == ',':\u000a                f = codecs.open(fileName + '.csv',\u000a                                writeFormat, encoding="utf-8")\u000a            else:\u000a                f = codecs.open(fileName + '.txt',\u000a                                writeFormat, encoding="utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of\u000a        # repetitions:\u000a\u000a        repsPerType = {}\u000a        for rep in range(self.nReps):\u000a            if self.trialWeights is None:\u000a                nRows = len(self.trialList)\u000a            else:\u000a                nRows = sum(self.trialWeights)\u000a\u000a            for trialN in range(nRows):\u000a                # find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                # determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex] = 0\u000a                else:\u000a                    repsPerType[trialTypeIndex] += 1\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g.\u000a                # subject ID, date, etc) repeated every line if it exists:\u000a                if self.extraInfo != None:\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can\u000a                # always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # what repeat are we on for this trial type?\u000a                trep = repsPerType[trialTypeIndex]\u000a                # collect the value from each trial of the vars in the header:\u000a                tti = trialTypeIndex\u000a                for prmName in header:\u000a                    # the header includes both trial and data variables, so\u000a                    # need to check before accessing:\u000a                    if self.trialList[tti] and prmName in self.trialList[tti]:\u000a                        nextEntry[prmName] = self.trialList[tti][prmName]\u000a                    elif prmName in self.data:\u000a                        if self.trialWeights is None:\u000a                            nextEntry[prmName] = self.data[prmName][tti][trep]\u000a                        else:\u000a                            firstRowIndex = sum(self.trialWeights[:tti])\u000a                            _tw = self.trialWeights[tti]\u000a                            row = firstRowIndex + rep % _tw\u000a                            col = int(rep / _tw)\u000a                            nextEntry[prmName] = self.data[prmName][row][col]\u000a                    else:\u000a                        # allow a null value if this parameter wasn't\u000a                        # explicitly stored on this trial:\u000a                        nextEntry[prmName] = ''\u000a\u000a                # store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0, "TrialNumber")\u000a        if self.extraInfo is not None:\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        # write a header row:\u000a        if not matrixOnly:\u000a            f.write(delim.join(header) + '\u005cn')\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            line = delim.join([unicode(trial[prm]) for prm in header])\u000a            f.write(line + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' % f.name)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). "\u000a                    "Please use `importConditions` for identical "\u000a                    "functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val) == 0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            # nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except Exception:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except Exception:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except Exception:\u000a        pass\u000a\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler`\u000a    `trialTypes` or to :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a\u000a        - .csv:  import as a comma-separated-value file\u000a            (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files.\u000a            No support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists\u000a            (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a\u000a        - "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        - "2:5"       # 2, 3, 4 (doesn't include last whole value)\u000a        - "-10:2:"    # tenth from last to the last in steps of 2\u000a        - slice(-10, 2, None)  # the same as above\u000a        - random(5) * 8  # five random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all\u000a        names are OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            msg = ('Conditions file %s: Missing parameter name(s); '\u000a                   'empty cell(s) in the first row?')\u000a            raise ImportError(msg % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK:\u000a                # tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %\u000a                                  (fileName, msg, os.linesep * 2, name))\u000a\u000a    if fileName in ['None', 'none', None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        msg = 'Conditions file not found: %s'\u000a        raise ImportError(msg % os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        with open(fileName, 'rU') as fileUniv:\u000a            # use pandas reader, which can handle commas in fields, etc\u000a            trialsArr = read_csv(fileUniv, encoding='utf-8')\u000a        # convert the resulting dataframe to a numpy recarray\u000a        trialsArr = trialsArr.to_records(index=False)\u000a        if trialsArr.shape == ():\u000a            # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        # convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                \u000a                if type(val) in [unicode, str]:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif type(val) == numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    # if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        # val = eval('%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                elif numpy.isnan(val): #if it is a numpy.nan, convert to None\u000a                        val = None\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU')  # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except Exception:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0]  # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                # type is correct, being .pkl\u000a                thisTrial[fieldName] = row[fieldN]\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel '\u000a                              'format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName, data_only=True)\u000a        except Exception:  # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        try:\u000a            # in new openpyxl (2.3.4+) get_highest_xx is deprecated\u000a            nCols = ws.max_column\u000a            nRows = ws.max_row\u000a        except:\u000a            # version openpyxl 1.5.8 (in Standalone 1.80) needs this\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a\u000a        # get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        # loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):  # skip header first row\u000a            thisTrial = {}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                # if it looks like a list or tuple, convert it\u000a                if (type(val) in (unicode, str) and\u000a                        (val.startswith('[') and val.endswith(']') or\u000a                         val.startswith('(') and val.endswith(')'))):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    # if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection) > 0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except Exception:\u000a                    raise TypeError("importConditions() was given some "\u000a                                    "`indices` but could not parse them")\u000a    # the selection might now be a slice or a series of indices\u000a    if isinstance(selection, slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection) > 0:\u000a        allConds = trialList\u000a        trialList = []\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList, fieldNames)\u000a    else:\u000a        return trialList\u000a\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys)\u000a    and levels (values) it will return a trialList in which all factors\u000a    have been factorially combined (so for example if there are two factors\u000a    with 3 and 5 levels the trialList will be a list of 3*5 = 15, each\u000a    specifying the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the\u000a            factors\u000a\u000a    Example::\u000a\u000a        factors={"text": ["red", "green", "blue"],\u000a                 "letterColor": ["red", "green"],\u000a                 "size": [0, 1]}\u000a        mytrials = createFactorialTrialList(factors)\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of\u000a    # lists\u000a    tempListOfLists = [[]]\u000a    for key in factors:\u000a        # this takes the levels of each factor as a set of values\u000a        # (a list) at a time\u000a        alist = factors[key]\u000a        tempList = []\u000a        for value in alist:\u000a            # now we loop over the values in a given list,\u000a            # and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key, value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]  # the even elements are keys\u000a        values = atrial[1::2]  # the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            # this combines the key with the value\u000a            atrialDict[keys[i]] = values[i]\u000a        # append one trial at a time to the final trialList\u000a        trialList.append(atrialDict)\u000a\u000a    return trialList\u000a\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to next() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have\u000a    been exceeded. If *stepSizes* was an array and has been exceeded\u000a    before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal\u000a    is reached. The values entered as arguments are then used.\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  # dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3,  # correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method='2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted.\u000a                If `stepSizes` is a list, but the minimum number of\u000a                reversals to perform, `nReversals`, is less than the\u000a                length of this list, PsychoPy will automatically increase\u000a                the minimum number of reversals and emit a warning.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array).\u000a                For a single value the step size is fixed. For an array or\u000a                list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the\u000a                staircase has not reached the required number of reversals\u000a                then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the\u000a                staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the\u000a                staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given\u000a                size in 'db', 'log' or 'lin' units ('lin' means this\u000a                intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin'\u000a                will simply add or subtract that amount each step, 'db'\u000a                and 'log' will step by a certain number of decibels or\u000a                log units (note that this will prevent your value ever\u000a                reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        self.name = name\u000a        self.startVal = startVal\u000a        self.nUp = nUp\u000a        self.nDown = nDown\u000a        self.extraInfo = extraInfo\u000a        self.method = method\u000a        self.stepType = stepType\u000a\u000a        try:\u000a            self.stepSizes = list(stepSizes)\u000a        except TypeError:\u000a            # stepSizes is not array-like / iterable, i.e., a scalar.\u000a            self.stepSizes = [stepSizes]\u000a\u000a        self._variableStep = True if len(self.stepSizes) > 1 else False\u000a        self.stepSizeCurrent = self.stepSizes[0]\u000a\u000a        if nReversals is not None and len(self.stepSizes) > nReversals:\u000a            logging.warn(\u000a                "Increasing number of minimum required reversals to "\u000a                "the number of step sizes (%i)." % len(self.stepSizes)\u000a            )\u000a            self.nReversals = len(self.stepSizes)\u000a        else:\u000a            self.nReversals = nReversals\u000a\u000a        # to terminate the nTrials must be exceeded and either\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.thisTrialN = -1\u000a        # a dict of lists where each should have the same length as the main\u000a        # data:\u000a        self.otherData = {}\u000a        self.data = []\u000a        self.intensities = []\u000a        self.reversalPoints = []\u000a        self.reversalIntensities = []\u000a        # initially it goes down but on every step:\u000a        self.currentDirection = 'start'\u000a        # correct since last stim change (minus are incorrect):\u000a        self.correctCounter = 0\u000a        self._nextIntensity = self.startVal\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        # a flag for the 1-up 1-down initial rule:\u000a        self.initialRule = 0\u000a\u000a        # self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use\u000a        the recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity != None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        # increment the counter of correct scores\u000a        if result == 1:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter += 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if len(self.data) > 1 and self.data[-2] == result:\u000a                # increment if on a run\u000a                self.correctCounter -= 1\u000a            else:\u000a                # or reset\u000a                self.correctCounter = -1\u000a\u000a        # add the current data to experiment if poss\u000a        if self.getExp() is not None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside\u000a        the result data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData:  # init the list\u000a            if self.thisTrialN > 0:\u000a                # might have run trals already\u000a                self.otherData[dataName] = [None] * (self.thisTrialN - 1)\u000a            else:\u000a                self.otherData[dataName] = []\u000a        # then add current value\u000a        self.otherData[dataName].append(value)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous.\u000a        Please use one of these instead:\u000a\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """Based on current intensity, counter of correct responses, and\u000a        current direction.\u000a        """\u000a\u000a        if len(self.reversalIntensities) < 1:\u000a            # always using a 1-down, 1-up rule initially\u000a            if self.data[-1] == 1:  # last answer correct\u000a                # got it right\u000a                if self.currentDirection == 'up':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'down' or 'start'\u000a                    reversal = False\u000a                self.currentDirection = 'down'\u000a            else:\u000a                # got it wrong\u000a                if self.currentDirection == 'down':\u000a                    reversal = True\u000a                else:\u000a                    # direction is 'up' or 'start'\u000a                    reversal = False\u000a                # now:\u000a                self.currentDirection = 'up'\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, time to go down!\u000a            if self.currentDirection != 'down':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'down'\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, time to go up!\u000a            # note current direction\u000a            if self.currentDirection != 'up':\u000a                reversal = True\u000a            else:\u000a                reversal = False\u000a            self.currentDirection = 'up'\u000a        else:\u000a            # same as previous trial\u000a            reversal = False\u000a\u000a        # add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities) < 1:\u000a                self.initialRule = 1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a\u000a        # test if we're done\u000a        if (len(self.reversalIntensities) >= self.nReversals and\u000a                len(self.intensities) >= self.nTrials):\u000a            self.finished = True\u000a        # new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                # we've gone beyond the list of step sizes\u000a                # so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                _sz = len(self.reversalIntensities)\u000a                self.stepSizeCurrent = self.stepSizes[_sz]\u000a\u000a        # apply new step size\u000a        if len(self.reversalIntensities) < 1 or self.initialRule == 1:\u000a            self.initialRule = 0  # reset the flag\u000a            if self.data[-1] == 1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown:\u000a            # n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:\u000a            # n wrong, so going up\u000a            self._intensityInc()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        if self.finished == False:\u000a            # check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key]) < self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent / 20.0)\u000a        elif self.stepType == 'log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        # check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter = 0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter\u000a        """\u000a        if self.stepType == 'db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent / 20.0)\u000a        if self.stepType == 'log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType == 'lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter = 0\u000a        # check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        # create the file or send to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding)\u000a\u000a        # write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace(reversalStr, ',', delim)\u000a        reversalStr = string.replace(reversalStr, '[', '')\u000a        reversalStr = string.replace(reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' % reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace(reversalPts, ',', delim)\u000a        reversalPts = string.replace(reversalPts, '[', '')\u000a        reversalPts = string.replace(reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' % reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace(rawIntens, ',', delim)\u000a        rawIntens = string.replace(rawIntens, '[', '')\u000a        rawIntens = string.replace(rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' % rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace(responses, ',', delim)\u000a        responses = string.replace(responses, '[', '')\u000a        responses = string.replace(responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' % responses)\u000a\u000a        # add self.extraInfo\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            # dict begins and ends with {} - remove\u000a            # string.replace(strInfo, '{','')\u000a            # strInfo = string.replace(strInfo, '}','')\u000a            strInfo = strInfo[1:-1]\u000a            # separate value from keyname\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')\u000a            # separate values from each other\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' % strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, sheetName='data',\u000a                    matrixOnly=False, appendFile=True,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files\u000a        (see :func:`TrialHandler.saveAsText()` ) that data can be stored\u000a        in multiple named sheets within the file. So you could have a\u000a        single file named after your experiment and then have one worksheet\u000a        for each participant. Or you could have one file for each participant\u000a        and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase / intensity level on *every*\u000a        trial and the corresponding responses of the participant on every\u000a        trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be\u000a                overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a        # NB this was based on the limited documentation for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in '\u000a                              'Excel (xlsx) format, but was not found.')\u000a            # return -1\u000a\u000a        # import necessary subpackages - they are small so won't matter to do\u000a        # it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName += '.xlsx'\u000a        # create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook = False\u000a        else:\u000a            if not appendFile:\u000a                # the file exists but we're not appending, will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()\u000a            wb.properties.creator = 'PsychoPy' + psychopy.__version__\u000a            newWorkbook = True\u000a\u000a        ew = ExcelWriter(workbook=wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title = sheetName\u000a        else:\u000a            ws = wb.create_sheet()\u000a            ws.title = sheetName\u000a\u000a        # write the data\u000a        # reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            _cell = _getExcelCellName(col=0, row=revN + 1)  # col 0\u000a            ws.cell(_cell).value = unicode(revIntens)\u000a            _cell = _getExcelCellName(col=1, row=revN + 1)  # col 1\u000a            ws.cell(_cell).value = unicode(self.reversalPoints[revN])\u000a\u000a        # trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2, row=intenN + 1)\u000a                    ).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3, row=intenN + 1)\u000a                    ).value = unicode(self.data[intenN])\u000a\u000a        # add self.extraInfo\u000a        rowN = 0\u000a        if self.extraInfo is not None and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6, row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key, val in self.extraInfo.items():\u000a                _cell = _getExcelCellName(col=6, row=rowN)\u000a                ws.cell(_cell).value = unicode(key) + u':'\u000a                _cell = _getExcelCellName(col=7, row=rowN)\u000a                ws.cell(_cell).value = unicode(val)\u000a                rowN += 1\u000a\u000a        ew.save(filename=fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' % fileName)\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    _e = -10**(beta * (x2 + xThreshold))\u000a    p2 = delta * gamma + (1-delta) * (1 - (1 - gamma) * exp(_e))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1,\u000a                                     pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50 / 50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma\u000a        # are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2,\u000a            pThreshold=0.63, gamma=0.01,\u000a            nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile()  # gets the median\u000a\u000a    """\u000a\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True,\u000a                 **kwargs):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase\u000a                (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull\u000a        psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold.\u000a                Be generous with the sd as QUEST will have trouble finding\u000a                the true threshold if it's more than one sd from your\u000a                initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of\u000a                response==1. An intensity offset is introduced into the\u000a                psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the\u000a                threshold estimate before stopping. If both this and\u000a                nTrials is specified, whichever happens first will\u000a                determine when Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test.\u000a                If you want to get a specific threshold level at the end\u000a                of your staircasing, please use the quantile, mean, and\u000a                mode methods directly.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when\u000a                intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest\u000a                intensity that the internal table can store. This interval\u000a                will be centered on the initial guess tGuess. QUEST assumes\u000a                that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with\u000a                collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be\u000a                used to prevent it reaching impossible contrast values,\u000a                for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results.\u000a                Might be useful to give the quest algorithm more information\u000a                if you have it. You can also call the importData function\u000a                directly.\u000a\u000a            Additional keyword arguments will be ignored.\u000a\u000a        :Notes:\u000a\u000a        The additional keyword arguments `**kwargs` might for example be\u000a        passed by the `MultiStairHandler`, which expects a `label` keyword\u000a        for each staircase. These parameters are to be ignored by the\u000a        StairHandler.\u000a\u000a        """\u000a        StairHandler.__init__(\u000a            self, startVal, nTrials=nTrials, extraInfo=extraInfo,\u000a            method=method, stepType='lin', minVal=minVal,\u000a            maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        self.stopInterval = stopInterval\u000a\u000a        startVal = startVal\u000a        startValSd = startValSd\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(\u000a            startVal, startValSd, pThreshold, beta, delta, gamma,\u000a            grain=grain, range=range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = intensity\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  # remove the auto-generated one\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a\u000a        self._checkFinished()\u000a        if not self.finished:\u000a            self.calculateNextIntensity()\u000a\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest\u000a        algorithm\u000a        """\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input "\u000a                                 "must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities, results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:\u000a                # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses\u000a        """\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if self._nextIntensity > self.maxVal and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif self._nextIntensity < self.minVal and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._nextIntensity\u000a\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._questNextIntensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf\u000a        """\u000a        return self._quest.mean()\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf\u000a        """\u000a        return self._quest.sd()\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf\u000a        """\u000a        return self._quest.mode()[0]\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf\u000a        """\u000a        return self._quest.quantile(p)\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval\u000a        """\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """returns a simulated user response to the next intensity level\u000a        presented by Quest, need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`,\u000a        `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a\u000a        StopIteration error. This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True:  # i.e. forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a        """\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif (self.stopInterval is not None and\u000a                self.confInterval(True) < self.stopInterval):\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """Handler to implement the "Psi" adaptive psychophysical method\u000a    (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function\u000a    to be a cumulative Gaussian. Psi estimates the two free parameters\u000a    of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution.\u000a    It chooses stimuli to present by minimizing the entropy of this grid.\u000a    Because this grid is represented internally as a 4-D array, one must\u000a    choose the intensity, alpha, and beta ranges carefully so as to avoid\u000a    a Memory Error. Maximum likelihood is used to estimate Lambda, the most\u000a    likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be\u000a    estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of\u000a    the Psi procedure. If the estimated alpha or beta values equal your\u000a    specified search bounds, then the search range most likely did not\u000a    contain the true value. In this situation the procedure should be\u000a    repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior\u000a    from existing research. A function to save the posterior over Lambda\u000a    as a Numpy binary file is included.\u000a\u000a    Kontsevich & Tyler (1999) specify their psychometric function in terms\u000a    of d'. PsiHandler avoids this and treats all parameters with respect\u000a    to stimulus intensity. Specifically, the forms of the psychometric\u000a    function assumed for Yes/No and Two Alternative Forced Choice (2AFC)\u000a    are, respectively:\u000a\u000a    _normCdf = norm.cdf(x, mean=alpha, sd=beta)\u000a    Y(x) = .5 * delta + (1 - delta) * _normCdf\u000a\u000a    Y(x) = .5 * delta + (1 - delta) * (.5 + .5 * _normCdf)\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 stepType='lin',\u000a                 expectedMin=0.5,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 extraInfo=None,\u000a                 name=''):\u000a        """Initializes the handler and creates an internal Psi Object for\u000a        grid approximation.\u000a\u000a        :Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of\u000a                the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the\u000a                stimuli intensity range. If stepType == 'log', this specifies\u000a                the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli\u000a                intensity range. If 'lin' then evenly spaced steps are used.\u000a                If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            expectedMin  (float)\u000a                The expected lower asymptote of the psychometric function\u000a                (PMF).\u000a\u000a                For a Yes/No task, the PMF usually extends across the\u000a                interval [0, 1]; here, `expectedMin` should be set to `0`.\u000a\u000a                For a 2-AFC task, the PMF spreads out across [0.5, 1.0].\u000a                Therefore, `expectedMin` should be set to `0.5` in this\u000a                case, and the 2-AFC psychometric function described above\u000a                going to be is used.\u000a\u000a                Currently, only Yes/No and 2-AFC designs are supported.\u000a\u000a                Defaults to 0.5, or a 2-AFC task.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the\u000a                Psi Object. This can either be a numpy.ndarray object or\u000a                the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in\u000a                logging system.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in\u000a                logging system.\u000a\u000a        :Raises:\u000a\u000a            NotImplementedError\u000a                If the supplied `minVal` parameter implies an experimental\u000a                design other than Yes/No or 2-AFC.\u000a\u000a        """\u000a        if expectedMin not in [0, 0.5]:\u000a            raise NotImplementedError(\u000a                'Currently, only Yes/No and 2-AFC designs are '\u000a                'supported. Please specify either `expectedMin=0` '\u000a                '(Yes/No) or `expectedMin=0.5` (2-AFC).')\u000a\u000a        StairHandler.__init__(\u000a            self, startVal=None, nTrials=nTrials, extraInfo=extraInfo,\u000a            stepType=stepType, minVal=intensRange[0],\u000a            maxVal=intensRange[1], name=name\u000a        )\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be "\u000a                                "read. Using a uniform prior instead.")\u000a                prior = None\u000a\u000a        twoAFC = True if expectedMin == 0.5 else False\u000a        self._psi = PsiObject(\u000a            intensRange, alphaRange, betaRange, intensPrecision,\u000a            alphaPrecision, betaPrecision, delta=delta,\u000a            stepType=stepType, TwoAFC=twoAFC, prior=prior)\u000a\u000a        self._psi.update(None)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial. Supplying an `intensity` value here\u000a        indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        # if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        # add the current data to experiment if possible\u000a        if self.getExp() is not None:\u000a            # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        """\u000a        self._checkFinished()\u000a        if self.finished == False:\u000a            # update pointer for next trial\u000a            self.thisTrialN += 1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)\u000a        """\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability.\u000a\u000a        The optional argument 'lamb' allows thresholds to be estimated\u000a        without having to recompute the maximum likelihood lambda.\u000a        """\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    msg = ("Invalid user-specified lambda pair. A "\u000a                           "new estimate of lambda will be computed.")\u000a                    warnings.warn(msg, SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                msg = ("Invalid user-specified lambda pair. A new "\u000a                       "estimate of lambda will be computed.")\u000a                warnings.warn(msg, SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves the posterior array over probLambda as a pickle file\u000a        with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the "\u000a                          "posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a\u000a    def __init__(self, stairType='simple', method='random',\u000a                 conditions=None, nTrials=50, originPath=None,\u000a                 name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures\u000a        (simple or QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant\u000a        :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above\u000a        handlers) a `label` to tag the staircase and a `startValSd`\u000a        (only for QUEST staircases). Any parameters not specified in the\u000a        conditions file will revert to the default for that individual\u000a        handler.\u000a\u000a        If you need to custom the behaviour further you may want to\u000a        look at the recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised\u000a                more than that (so you can't have 3 repeats of the same\u000a                staircase in a row unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using\u000a                `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and\u000a                'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should\u000a                be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase\u000a                hasn't also met its minimal reversals.\u000a                See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                # do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)  # this is ESSENTIAL\u000a\u000a            # save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)  # easy to browse\u000a            stairs.saveAsPickle(fileName)  # contains more info\u000a\u000a        """\u000a        self.name = name\u000a        self.autoLog = autoLog\u000a        self.type = stairType\u000a        self.method = method  # 'random' or 'sequential'\u000a        self.conditions = conditions\u000a        self.nTrials = nTrials\u000a        self.finished = False\u000a        self.totalTrials = 0\u000a        self._checkArguments()\u000a        # create staircases\u000a        self.staircases = []  # all staircases\u000a        self.runningStaircases = []  # staircases that haven't finished yet\u000a        self.thisPassRemaining = []  # staircases to run this pass\u000a        self._createStairs()\u000a\u000a        # fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]  # take the first\u000a        # gets updated by self.addData()\u000a        self._nextIntensity = self.currentStaircase._nextIntensity\u000a        # store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None  # the experiment handler that owns me!\u000a\u000a    def _checkArguments(self):\u000a        # Did we get a `conditions` parameter, correctly formatted?\u000a        if not isinstance(self.conditions, collections.Iterable):\u000a            raise TypeError(\u000a                '`conditions` parameter passed to MultiStairHandler '\u000a                'should be a list, not a %s.' % type(self.conditions))\u000a\u000a        c0 = self.conditions[0]\u000a        if type(c0) != dict:\u000a            raise TypeError(\u000a                '`conditions` passed to MultiStairHandler should be a '\u000a                'list of python dictionaries, not a list of %ss.' %\u000a                type(c0))\u000a\u000a        # Did `conditions` contain the things we need?\u000a        params = c0.keys()\u000a        if self.type not in ['simple', 'quest', 'QUEST']:\u000a            raise ValueError(\u000a                'MultiStairHandler `stairType` should be \u005c'simple\u005c', '\u000a                '\u005c'QUEST\u005c' or \u005c'quest\u005c', not \u005c'%s\u005c'' % self.type)\u000a\u000a        if 'startVal' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called '\u000a                                 '`startVal` in conditions')\u000a        if 'label' not in params:\u000a            raise AttributeError('MultiStairHandler needs a parameter called'\u000a                                 ' `label` in conditions')\u000a        if self.type in ['QUEST', 'quest'] and 'startValSd' not in params:\u000a            raise AttributeError(\u000a                'MultiStairHandler needs a parameter called '\u000a                '`startValSd` in conditions for QUEST staircases.')\u000a\u000a    def _createStairs(self):\u000a        for condition in self.conditions:\u000a            # We create a copy, because we are going to remove items from\u000a            # this dictionary in this loop, but don't want these\u000a            # changes to alter the originals in self.conditions.\u000a            args = dict(condition)\u000a\u000a            # If no individual `nTrials` parameter was supplied for this\u000a            # staircase, use the `nTrials` that were passed to\u000a            # the MultiStairHandler on instantiation.\u000a            if 'nTrials' not in args:\u000a                args['nTrials'] = self.nTrials\u000a\u000a            if self.type == 'simple':\u000a                startVal = args.pop('startVal')\u000a                thisStair = StairHandler(startVal, **args)\u000a            elif self.type in ['QUEST', 'quest']:\u000a                startVal = args.pop('startVal')\u000a                startValSd = args.pop('startValSd')\u000a                thisStair = QuestHandler(startVal, startValSd, **args)\u000a\u000a            # This isn't normally part of handler.\u000a            thisStair.condition = condition\u000a\u000a            # And finally, add it to the list.\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a\u000a    def __iter__(self):\u000a        return self\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:  # automatically stops when done\u000a                # do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True:  # ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:  # we got a StopIteration error\u000a                    break  # break out of the forever loop\u000a                # do stuff here for the trial\u000a\u000a        """\u000a        # create a new set for this pass if needed\u000a        if (not hasattr(self, 'thisPassRemaining') or\u000a                not self.thisPassRemaining):\u000a            if self.runningStaircases:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished = True\u000a                raise StopIteration\u000a\u000a        # fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(\u000a            0)  # take the first and remove it\u000a        # if staircase.next() not called, staircaseHandler would not\u000a        # save the first intensity,\u000a        # Error: miss align intensities and responses\u000a        # gets updated by self.addResponse()\u000a        self._nextIntensity = self.currentStaircase.next()\u000a\u000a        # return value\u000a        if not self.finished:\u000a            # inform experiment of the condition (but not intensity,\u000a            # that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" % (self.name, key), value)\u000a                exp.addData(self.name + '.thisIndex',\u000a                            self.conditions.index(stair.condition))\u000a                exp.addData(self.name + '.thisRepN', stair.thisTrialN + 1)\u000a                exp.addData(self.name + '.thisN', self.totalTrials)\u000a                exp.addData(self.name + '.direction', stair.currentDirection)\u000a                exp.addData(self.name + '.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name + '.stepType', stair.stepType)\u000a                exp.addData(self.name + '.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method == 'random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct / detected or\u000a        incorrect / missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        # add the current data to experiment if poss\u000a        if self.getExp() != None:  # update the experiment handler too\u000a            self.getExp().addData(self.name + ".response", result)\u000a        self.totalTrials += 1\u000a\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to\u000a        control the staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding\u000a        the response (0 or 1) or some other data concerning the trial so\u000a        there is now a pair of explicit methods:\u000a\u000a            addResponse(corr,intensity) #some data that alters the next\u000a                trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't\u000a                control staircase\u000a\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in (str, unicode):\u000a            raise TypeError("MultiStairHandler.addData should only receive "\u000a                            "corr / incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no '\u000a                              'trials completed. Nothing saved')\u000a            return -1\u000a\u000a        # otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName += '.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """Save a summary data file in Excel OpenXML format workbook\u000a        (:term:`xlsx`) for processing in most spreadsheet packages.\u000a        This format is compatible with versions of Excel (2007 or greater)\u000a        and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see\u000a        :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level\u000a        ('intensity') at each reversal, a list of reversal indices\u000a        (trial numbers), the raw staircase/intensity level on *every* trial\u000a        and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include\u000a                relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output\u000a                (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten.\u000a                If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will\u000a                be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no'\u000a                              ' trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append = appendFile\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self, fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to\u000a                :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file.\u000a                Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials < 1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials'\u000a                              ' completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName + "_" + label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                    delim='\u005ct',\u000a                    matrixOnly=False):\u000a        """Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted,\u000a                ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided\u000a                at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True  # no header info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            # make a filename\u000a            label = thisStair.condition['label']\u000a            print("\u005cn%s:" % label)\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                                 matrixOnly=thisMatrixOnly)\u000a\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set\u000a    True for missing entries. When any non-numeric data (string, list or\u000a    array) get inserted using DataHandler.add(val) the array is converted\u000a    to a standard (not masked) numpy array with dtype='O' and where missing\u000a    entries have value = "--".\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials = trials\u000a        self.dataTypes = []  # names will be added during addDataType\u000a        self.isNumeric = {}\u000a        # if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape = dataShape\u000a        elif self.trials:\u000a            self.dataShape = list(numpy.asarray(trials.trialList, 'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        # initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of particular shape if\u000a        specified (otherwise the shape of the trial matrix in the trial\u000a        handler. Data are initialised to be zero everywhere. Not needed\u000a        by user: appropriate types will be added during initialisation\u000a        and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names, basestring):\u000a            # recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            # create the appropriate array in the dict\u000a            # initially use numpy masked array of floats with mask=True\u000a            # for missing vals. convert to a numpy array with dtype='O'\u000a            # if non-numeric data given. NB don't use masked array with\u000a            # dytpe='O' together - they don't unpickle\u000a            self[names] = numpy.ma.zeros(shape, 'f')  # masked array of floats\u000a            self[names].mask = True\u000a            # add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names] = True  # until we need otherwise\u000a\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            # 'ran' is always the first thing to update\u000a            repN = sum(self['ran'][self.trials.thisIndex])\u000a            if thisType != 'ran':\u000a                # because it has already been updated\u000a                repN -= 1\u000a            # make a list where 1st digit is trial number\u000a            position = [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        # check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr < shapeArr):\u000a            # array isn't big enough\u000a            logging.warning('need a bigger array for: ' + thisType)\u000a            # not implemented yet!\u000a            self[thisType] = extendArr(self[thisType], posArr)\u000a        # check for ndarrays with more than one value and for non-numeric data\u000a        if (self.isNumeric[thisType] and\u000a                ((type(value) == numpy.ndarray and len(value) > 1) or\u000a                 (type(value) not in [float, int]))):\u000a            self._convertToObjectArray(thisType)\u000a        # insert the value\u000a        self[thisType][position[0], int(position[1])] = value\u000a\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked\u000a        object array\u000a        """\u000a        dat = self[thisType]\u000a        # create an array of Object type\u000a        self[thisType] = numpy.array(dat.data, dtype='O')\u000a        # masked vals should be "--", others keep data\u000a        # we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self[thisType] = numpy.where(dat.mask, '--', dat).astype('O')\u000a        self.isNumeric[thisType] = False\u000a\u000a\u000aclass FitFunction(object):\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use"\u000a                                 " FitLogistic, FitWeibull etc instead")\u000a\u000a\u000aclass _baseFunctionFit(object):\u000a    """Not needed by most users except as a superclass for developing\u000a    your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        super(_baseFunctionFit, self).__init__()\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq = 0\u000a        self.rms = 0\u000a        self.chi = 0\u000a        # do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        # get some useful variables to help choose starting fit vals\u000a        # self.params = optimize.fmin_powell(self._getErr, self.params,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        # self.params = optimize.fmin_bfgs(self._getErr, self.params, None,\u000a        #    (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(\u000a            self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq / len(self.xx)\u000a\u000a    def _getErr(self, params, xx, yy, sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy - mod)**2 / sems)\u000a        return err\u000a\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for\u000a        arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        #_eval is a static method - must be done this way because the\u000a        # curve_fit function doesn't want to have any `self` object as\u000a        # first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model,\u000a        or for arbitrary params if these are given.\u000a        """\u000a        if params is None:\u000a            # so the user can set params for this particular inv\u000a            params = self.params\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1.0 - _chance) * (1 - numpy.exp(-(xx / alpha)**beta))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0 - yy) / (1 - _chance))) ** (1.0 / beta)\u000a        return xx\u000a\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax - rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy - rMin) / (rMax - rMin)  # remove baseline and scale\u000a        # do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1 - yScaled))**(1 / n)\u000a        return xx\u000a\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1 - chance) / (1 + numpy.exp((PSE - xx) * JND))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1 - _chance) / (yy - _chance) - 1) / JND\u000a        return xx\u000a\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params (a list\u000a    with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is\u000a    more in with the parameters for the Weibull fit, for instance, it is less\u000a    in keeping with standard expectations of normal (Gaussian distributions)\u000a    so in version 1.74.00 the parameters became the [centre,sd] of the normal\u000a    distribution.\u000a\u000a    """\u000a    # static methods have no `self` and this is important for\u000a    # optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        # NB numpy.special.erf() goes from -1:1\u000a        yy = (_chance + (1 - _chance) *\u000a              ((special.erf((xx - xShift) / (numpy.sqrt(2) * sd)) + 1) * 0.5))\u000a        return yy\u000a\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        # xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        # NB: numpy.special.erfinv() goes from -1:1\u000a        xx = (xShift + numpy.sqrt(2) * sd *\u000a              special.erfinv(((yy - _chance) / (1 - _chance) - 0.5) * 2))\u000a        return xx\u000a\u000a######################### End psychopy.data classes #########################\u000a\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each\u000a            column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape) == 1:\u000a        # have presumably been given a series of data for one stimulus\u000a        # adds a dimension (arraynow has shape (1,Ntrials))\u000a        dat = numpy.array([dat])\u000a\u000a    nTrials = dat.shape[1]\u000a    # initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape + (n,), dat.dtype)\u000a    rand = numpy.random.rand\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN, :]  # fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials * rand(nTrials)).astype('i')\u000a            resamples[stimulusN, :, sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000a\u000adef functionFromStaircase(intensities, responses, bins=10):\u000a    """Create a psychometric function by binning data from a staircase\u000a    procedure. Although the default is 10 bins Jon now always uses 'unique'\u000a    bins (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities,\u000a                                                          responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent\u000a                intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique'\u000a                (each bin is made from aa data for exactly one intensity\u000a                value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center\u000a                of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    # convert to arrays\u000a    try:\u000a        # concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except Exception:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    # sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens = numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities == thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities) / float(bins)\u000a        for binN in range(bins):\u000a            start = int(round(binN * pointsPerBin))\u000a            stop = int(round((binN + 1) * pointsPerBin))\u000a            thisResp = sortedResp[start:stop]\u000a            thisInten = sortedInten[start:stop]\u000a            binnedResp.append(numpy.mean(thisResp))\u000a            binnedInten.append(numpy.mean(thisInten))\u000a            nPoints.append(len(thisInten))\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M")\u000a    returns '2011_Mar_16_1307' depending on locale, can have unicode chars\u000a    in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_decoded = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        # '2011_03_16_1307'\u000a        now_decoded = time.strftime("%Y_%m_%d_%H%M", time.localtime())\u000a\u000a    return now_decoded\u000a\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder)  # spit an error if we fail\u000a    return True\u000a\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in (str, unicode, numpy.string_, numpy.unicode_):\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name = str(name)  # convert from unicode if possible\u000a    except Exception:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            msg = ("name %s (type %s) contains non-ASCII characters"\u000a                   " (e.g. accents)")\u000a            raise AttributeError(msg % (name, type(name)))\u000a        else:\u000a            msg = "name %s (type %s) could not be converted to a string"\u000a            raise AttributeError(msg % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ''\u000a\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    # BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    return "%s%i" % (get_column_letter(col + 1), row + 1)\u000a
p399
sg77
I1
sg69
Nsg78
(lp400
F2.523829377920773
aF4
aF1.0047545726038318
aF1.5924286822139888
aF0.63395727698444526
aF1.0047545726038318
asg80
(lp401
I4
asg82
I1
sg83
F4
sg84
F0.63395727698444526
sg43
I01
sg85
g86
sg87
S'None'
p402
sg89
I4
sg90
I0
sg91
Nsg92
F0.050000000000000003
sg93
(dp403
g95
(lp404
I1
aI1
aI1
aI1
aI1
aI1
aI1
aI1
aI1
aI1
asg97
(lp405
g378
ag378
ag378
ag378
ag378
ag378
ag378
ag378
ag378
ag378
assg105
I00
sg106
S'db'
p406
sg108
(lp407
I01
aI00
aI01
aI01
aI01
aI00
aI01
aI01
aI00
aI01
asg97
(dp408
S'maxVal'
p409
g402
sS'nDown'
p410
I1
sS'staircase'
p411
S'main'
p412
sS'minVal'
p413
F0.050000000000000003
sS'stepType'
p414
g406
sS'label'
p415
S'hard'
p416
sS'stepSizes'
p417
I4
sS'nUp'
p418
I1
sS'startVal'
p419
F1.2649110640673515
sS'condition'
p420
S'Environmental'
p421
ssg124
(lp422
I1
aI2
aI5
aI6
aI8
aI9
asg6
g126
sg11
S''
sg44
Nsg127
g128
sg129
I00
sg130
(lp423
F4
aF2.523829377920773
aF4
aF2.523829377920773
aF1.5924286822139888
aF1.0047545726038318
aF1.5924286822139888
aF1.0047545726038318
aF0.63395727698444526
aF1.0047545726038318
asg132
I0
sg133
I100
sg134
I9
sbasg162
(lp424
sg164
g165
sg43
I01
sg166
g368
sg105
I00
sg167
(lp425
g368
ag397
asg133
I100
sg169
(lp426
g381
ag408
asg85
g171
sg84
F0.63395727698444526
sbasS'saveWideText'
p427
I00
sS'thisEntry'
p428
(dp429
S'.stepSizes'
p430
I4
sg25
I0
sS'.startVal'
p431
F2.004748934509089
sS'.maxVal'
p432
g373
sg27
I19
sS'.stepType'
p433
g379
sg28
g128
sg26
I10
sS'.condition'
p434
g394
sS'.minVal'
p435
F0.050000000000000003
sg30
F0.63395727698444526
sS'.label'
p436
g389
sg29
I4
sS'.staircase'
p437
g385
sS'.nDown'
p438
I1
sS'.nUp'
p439
I3
ssS'version'
p440
S''
sS'_paramNamesSoFar'
p441
(lp442
sS'entries'
p443
(lp444
(dp445
g21
I4
sg23
F2
sg28
S'start'
p446
sg40
I01
sg32
g99
(g100
(S'f8'
I0
I1
tRp447
(I3
S'<'
NNNI-1
I-1
I0
tbS'\x00G\xb8=\xdf\xdf\x05@'
tRp448
sg29
I4
sg50
g51
sg31
g99
(g447
S'DDDDDD\xfc?'
tRp449
sg41
F76.839874982833862
sg18
F0.050000000000000003
sg15
g88
sg38
S'right'
p450
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I0
sg34
I1
sg19
g107
sg52
g53
sg39
Vduel
p451
sg17
g114
sg22
I3
sg26
I1
sg48
g49
sg24
g123
sg30
F2
sg20
g118
sg37
S'duel'
p452
sg16
I1
sa(dp453
S'.stepSizes'
p454
I4
sS'.startVal'
p455
F2
sg28
g446
sg40
I00
sg32
g99
(g447
S'D\xbfi\x81\xdc\x9b\x01@'
tRp456
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x99\x99\x99\x99\x99\x99\xf1?'
tRp457
sg41
F86.823324918746948
sS'.minVal'
p458
F0.050000000000000003
sS'.maxVal'
p459
g140
sg38
S'down'
p460
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I1
sg34
I1
sS'.stepType'
p461
g144
sg52
g53
sg39
Vride
p462
sS'.staircase'
p463
g150
sS'.nUp'
p464
I1
sg26
I1
sg48
g49
sS'.condition'
p465
g159
sg30
F2
sS'.label'
p466
g154
sg37
S'dried'
p467
sS'.nDown'
p468
I1
sa(dp469
S'.stepSizes'
p470
I4
sS'.startVal'
p471
F2
sg28
g296
sg40
I01
sg32
g99
(g447
S"\x99'\n\x15XY\xf1?"
tRp472
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xbd?'
tRp473
sg41
F95.983214139938354
sS'.minVal'
p474
F0.050000000000000003
sS'.maxVal'
p475
g140
sg38
S'up'
p476
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I2
sg34
I1
sS'.stepType'
p477
g144
sg52
g53
sg39
Vmain
p478
sS'.staircase'
p479
g150
sS'.nUp'
p480
I1
sg26
I2
sg48
g49
sS'.condition'
p481
g159
sg30
F3.1697863849222272
sS'.label'
p482
g154
sg37
S'main'
p483
sS'.nDown'
p484
I1
sa(dp485
S'.stepSizes'
p486
I4
sS'.startVal'
p487
F2
sg28
g128
sg40
I01
sg32
g99
(g447
S'$\xe1h\x9baW\x05@'
tRp488
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xaa\xaa\xaa\xaa\xaa\xaa\xfa?'
tRp489
sg41
F106.50315999984741
sS'.minVal'
p490
F0.050000000000000003
sS'.maxVal'
p491
g88
sg38
S'left'
p492
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I3
sg34
I1
sS'.stepType'
p493
g107
sg52
g53
sg39
Vbrink
p494
sS'.staircase'
p495
g114
sS'.nUp'
p496
I3
sg26
I2
sg48
g49
sS'.condition'
p497
g123
sg30
F1.2619146889603865
sS'.label'
p498
g118
sg37
S'brink'
p499
sS'.nDown'
p500
I1
sa(dp501
S'.stepSizes'
p502
I4
sS'.startVal'
p503
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'\xd1H\x84\xa9\r\xf4\xfa?'
tRp504
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xcd\xcc\xcc\xcc\xcc\xcc\xdc?'
tRp505
sg41
F116.74277710914612
sS'.minVal'
p506
F0.050000000000000003
sS'.maxVal'
p507
g88
sg38
S'right'
p508
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I4
sg34
I1
sS'.stepType'
p509
g107
sg52
g53
sg39
Vslain
p510
sS'.staircase'
p511
g114
sS'.nUp'
p512
I3
sg26
I3
sg48
g49
sS'.condition'
p513
g123
sg30
F0.79621434110699441
sS'.label'
p514
g118
sg37
S'sprain'
p515
sS'.nDown'
p516
I1
sa(dp517
S'.stepSizes'
p518
I4
sS'.startVal'
p519
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'\xc4\xfd;\xc2X\x02\x00@'
tRp520
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xbc\xbb\xbb\xbb\xbb\xbb\xeb?'
tRp521
sg41
F126.23870301246643
sS'.minVal'
p522
F0.050000000000000003
sS'.maxVal'
p523
g140
sg38
S'left'
p524
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I5
sg34
I1
sS'.stepType'
p525
g144
sg52
g53
sg39
Vtick
p526
sS'.staircase'
p527
g150
sS'.nUp'
p528
I1
sg26
I3
sg48
g49
sS'.condition'
p529
g159
sg30
F2
sS'.label'
p530
g154
sg37
S'pick'
p531
sS'.nDown'
p532
I1
sa(dp533
S'.stepSizes'
p534
I4
sS'.startVal'
p535
F2
sg28
g296
sg40
I00
sg32
g99
(g447
S'1O)\xcf\xeaX\xf9?'
tRp536
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xef\xee\xee\xee\xee\xee\xe6?'
tRp537
sg41
F135.46253204345703
sS'.minVal'
p538
F0.050000000000000003
sS'.maxVal'
p539
g88
sg38
S'left'
p540
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I6
sg34
I1
sS'.stepType'
p541
g107
sg52
g53
sg39
Vgold
p542
sS'.staircase'
p543
g114
sS'.nUp'
p544
I3
sg26
I4
sg48
g49
sS'.condition'
p545
g123
sg30
F1.2619146889603865
sS'.label'
p546
g118
sg37
S'told'
p547
sS'.nDown'
p548
I1
sa(dp549
S'.stepSizes'
p550
I4
sS'.startVal'
p551
F2
sg28
g296
sg40
I01
sg32
g99
(g447
S'KM\x12}L\xb0\xfa?'
tRp552
sg29
I4
sg50
g51
sg31
g99
(g447
S'333333\xd3?'
tRp553
sg41
F144.56636595726013
sS'.minVal'
p554
F0.050000000000000003
sS'.maxVal'
p555
g140
sg38
S'left'
p556
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I7
sg34
I1
sS'.stepType'
p557
g144
sg52
g53
sg39
Vstride
p558
sS'.staircase'
p559
g150
sS'.nUp'
p560
I1
sg26
I4
sg48
g49
sS'.condition'
p561
g159
sg30
F3.1697863849222272
sS'.label'
p562
g154
sg37
S'stride'
p563
sS'.nDown'
p564
I1
sa(dp565
S'.stepSizes'
p566
I4
sS'.startVal'
p567
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'\x9a\x99\xa8ff&\xf6?'
tRp568
sg29
I4
sg50
g51
sg31
g99
(g447
S'ffffff\xd6?'
tRp569
sg41
F154.18225908279419
sS'.minVal'
p570
F0.050000000000000003
sS'.maxVal'
p571
g140
sg38
S'up'
p572
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I8
sg34
I1
sS'.stepType'
p573
g144
sg52
g53
sg39
Vchose
p574
sS'.staircase'
p575
g150
sS'.nUp'
p576
I1
sg26
I5
sg48
g49
sS'.condition'
p577
g159
sg30
F2
sS'.label'
p578
g154
sg37
S'hose'
p579
sS'.nDown'
p580
I1
sa(dp581
S'.stepSizes'
p582
I4
sS'.startVal'
p583
F2
sg28
g296
sg40
I00
sg32
g99
(g447
S'\x0e9\x0c\x0f\xcah\x06@'
tRp584
sg29
I4
sg50
g51
sg31
g99
(g447
S'""""""\xfa?'
tRp585
sg41
F164.45416498184204
sS'.minVal'
p586
F0.050000000000000003
sS'.maxVal'
p587
g88
sg38
S'left'
p588
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I9
sg34
I1
sS'.stepType'
p589
g107
sg52
g53
sg39
Vthink
p590
sS'.staircase'
p591
g114
sS'.nUp'
p592
I3
sg26
I5
sg48
g49
sS'.condition'
p593
g123
sg30
F1.2619146889603865
sS'.label'
p594
g118
sg37
S'thing'
p595
sS'.nDown'
p596
I1
sa(dp597
S'.stepSizes'
p598
I4
sS'.startVal'
p599
F2
sg28
g446
sg40
I01
sg32
g99
(g447
S'\x99\x14\xbf\xd61\xf1\x06@'
tRp600
sg29
I4
sg50
g51
sg31
g99
(g447
S'DDDDDD\xfc?'
tRp601
sg41
F174.55795502662659
sS'.minVal'
p602
F0.050000000000000003
sS'.maxVal'
p603
g180
sg38
S'up'
p604
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I0
sg34
I1
sS'.stepType'
p605
g188
sg52
g53
sg39
Veshe
p606
sS'.staircase'
p607
g194
sS'.nUp'
p608
I3
sg26
I1
sg48
g49
sS'.condition'
p609
g203
sg30
F2
sS'.label'
p610
g198
sg37
S'eshe'
p611
sS'.nDown'
p612
I1
sa(dp613
S'.stepSizes'
p614
I4
sS'.startVal'
p615
F2
sg28
g446
sg40
I01
sg32
g99
(g447
S'\x140s\xa3\xe2\xac\x04@'
tRp616
sg29
I4
sg50
g51
sg31
g99
(g447
S'DDDDDD\xf8?'
tRp617
sg41
F184.60569596290588
sS'.minVal'
p618
F0.050000000000000003
sS'.maxVal'
p619
g211
sg38
S'right'
p620
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I1
sg34
I1
sS'.stepType'
p621
g215
sg52
g53
sg39
Vaya
p622
sS'.staircase'
p623
g221
sS'.nUp'
p624
I1
sg26
I1
sg48
g49
sS'.condition'
p625
g230
sg30
F2
sS'.label'
p626
g225
sg37
S'aya'
p627
sS'.nDown'
p628
I1
sa(dp629
S'.stepSizes'
p630
I4
sS'.startVal'
p631
F2
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xae\xb7#0\xa5\x12\x01@'
tRp632
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xf5?'
tRp633
sg41
F193.73349595069885
sS'.minVal'
p634
F0.050000000000000003
sS'.maxVal'
p635
g180
sg38
S'down'
p636
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I2
sg34
I1
sS'.stepType'
p637
g188
sg52
g53
sg39
Vishi
p638
sS'.staircase'
p639
g194
sS'.nUp'
p640
I3
sg26
I2
sg48
g49
sS'.condition'
p641
g203
sg30
F1.2619146889603865
sS'.label'
p642
g198
sg37
S'ishi'
p643
sS'.nDown'
p644
I1
sa(dp645
S'.stepSizes'
p646
I4
sS'.startVal'
p647
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'f\xad\x1e\xa4EF\x04@'
tRp648
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x11\x11\x11\x11\x11\x11\xf9?'
tRp649
sg41
F203.20545792579651
sS'.minVal'
p650
F0.050000000000000003
sS'.maxVal'
p651
g211
sg38
S'up'
p652
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I3
sg34
I1
sS'.stepType'
p653
g215
sg52
g53
sg39
Vana
p654
sS'.staircase'
p655
g221
sS'.nUp'
p656
I1
sg26
I2
sg48
g49
sS'.condition'
p657
g230
sg30
F1.2619146889603865
sS'.label'
p658
g225
sg37
S'asha'
p659
sS'.nDown'
p660
I1
sa(dp661
S'.stepSizes'
p662
I4
sS'.startVal'
p663
F2
sg28
g296
sg40
I01
sg32
g99
(g447
S'Xb\xce\xdaO\xbd\x01@'
tRp664
sg29
I4
sg50
g51
sg31
g99
(g447
S'333333\xf7?'
tRp665
sg41
F212.67722201347351
sS'.minVal'
p666
F0.050000000000000003
sS'.maxVal'
p667
g211
sg38
S'right'
p668
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I4
sg34
I1
sS'.stepType'
p669
g215
sg52
g53
sg39
Veke
p670
sS'.staircase'
p671
g221
sS'.nUp'
p672
I1
sg26
I3
sg48
g49
sS'.condition'
p673
g230
sg30
F2
sS'.label'
p674
g225
sg37
S'eke'
p675
sS'.nDown'
p676
I1
sa(dp677
S'.stepSizes'
p678
I4
sS'.startVal'
p679
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'!0\x1d\xf0\xfd4\x05@'
tRp680
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x88\x88\x88\x88\x88\x88\xfc?'
tRp681
sg41
F222.37307000160217
sS'.minVal'
p682
F0.050000000000000003
sS'.maxVal'
p683
g180
sg38
S'down'
p684
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I5
sg34
I1
sS'.stepType'
p685
g188
sg52
g53
sg39
Vichi
p686
sS'.staircase'
p687
g194
sS'.nUp'
p688
I3
sg26
I3
sg48
g49
sS'.condition'
p689
g203
sg30
F0.79621434110699441
sS'.label'
p690
g198
sg37
S'iti'
p691
sS'.nDown'
p692
I1
sa(dp693
S'.stepSizes'
p694
I4
sS'.startVal'
p695
F2
sg28
g296
sg40
I01
sg32
g99
(g447
S'\xe0\xfc?p\xafy\x01@'
tRp696
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xf1?'
tRp697
sg41
F232.29295992851257
sS'.minVal'
p698
F0.050000000000000003
sS'.maxVal'
p699
g180
sg38
S'down'
p700
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I6
sg34
I1
sS'.stepType'
p701
g188
sg52
g53
sg39
Voto
p702
sS'.staircase'
p703
g194
sS'.nUp'
p704
I3
sg26
I4
sg48
g49
sS'.condition'
p705
g203
sg30
F1.2619146889603865
sS'.label'
p706
g198
sg37
S'oto'
p707
sS'.nDown'
p708
I1
sa(dp709
S'.stepSizes'
p710
I4
sS'.startVal'
p711
F2
sg28
g128
sg40
I01
sg32
g99
(g447
S'Q\xbf=\xf3\x17K\xec?'
tRp712
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x9a\x99\x99\x99\x99\x99\xa9?'
tRp713
sg41
F242.78079199790955
sS'.minVal'
p714
F0.050000000000000003
sS'.maxVal'
p715
g211
sg38
S'right'
p716
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I7
sg34
I1
sS'.stepType'
p717
g215
sg52
g53
sg39
Vele
p718
sS'.staircase'
p719
g221
sS'.nUp'
p720
I1
sg26
I4
sg48
g49
sS'.condition'
p721
g230
sg30
F1.2619146889603865
sS'.label'
p722
g225
sg37
S'ele'
p723
sS'.nDown'
p724
I1
sa(dp725
S'.stepSizes'
p726
I4
sS'.startVal'
p727
F2
sg28
g128
sg40
I01
sg32
g99
(g447
S'v\x85rES\x8a\x00@'
tRp728
sg29
I4
sg50
g51
sg31
g99
(g447
S'333333\xf3?'
tRp729
sg41
F252.9006130695343
sS'.minVal'
p730
F0.050000000000000003
sS'.maxVal'
p731
g180
sg38
S'down'
p732
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I8
sg34
I1
sS'.stepType'
p733
g188
sg52
g53
sg39
Vete
p734
sS'.staircase'
p735
g194
sS'.nUp'
p736
I3
sg26
I5
sg48
g49
sS'.condition'
p737
g203
sg30
F0.79621434110699441
sS'.label'
p738
g198
sg37
S'ete'
p739
sS'.nDown'
p740
I1
sa(dp741
S'.stepSizes'
p742
I4
sS'.startVal'
p743
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S"\x82\xf77'\xe8\x14\xf9?"
tRp744
sg29
I4
sg50
g51
sg31
g99
(g447
S'EDDDDD\xe4?'
tRp745
sg41
F262.92442893981934
sS'.minVal'
p746
F0.050000000000000003
sS'.maxVal'
p747
g211
sg38
S'left'
p748
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I9
sg34
I1
sS'.stepType'
p749
g215
sg52
g53
sg39
Vulu
p750
sS'.staircase'
p751
g221
sS'.nUp'
p752
I1
sg26
I5
sg48
g49
sS'.condition'
p753
g230
sg30
F0.79621434110699441
sS'.label'
p754
g225
sg37
S'umu'
p755
sS'.nDown'
p756
I1
sa(dp757
S'.stepSizes'
p758
I2
sS'.startVal'
p759
F4
sg28
g446
sg40
I01
sg32
g99
(g447
S'\x00\x00\x00\x00\x00\x00\x00@'
tRp760
sg29
I2
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xf0?'
tRp761
sg41
F272.7322199344635
sS'.minVal'
p762
F0.050000000000000003
sS'.maxVal'
p763
g244
sg38
S'left'
p764
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I0
sg34
I1
sS'.stepType'
p765
g252
sg52
g53
sg39
Vsoda can
p766
sS'.staircase'
p767
g258
sS'.nUp'
p768
I3
sg26
I1
sg48
g49
sS'.condition'
p769
g267
sg30
F4
sS'.label'
p770
g262
sg37
S'soda can'
p771
sS'.nDown'
p772
I1
sa(dp773
S'.stepSizes'
p774
I2
sS'.startVal'
p775
F4
sg28
g446
sg40
I01
sg32
g99
(g447
S'\xf2L,M\x9c}\xf8?'
tRp776
sg29
I2
sg50
g51
sg31
g99
(g447
S'\xab\xaa\xaa\xaa\xaa\xaa\xe2?'
tRp777
sg41
F282.50808501243591
sS'.minVal'
p778
F0.050000000000000003
sS'.maxVal'
p779
g275
sg38
S'up'
p780
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I1
sg34
I1
sS'.stepType'
p781
g279
sg52
g53
sg39
Vboat horn
p782
sS'.staircase'
p783
g285
sS'.nUp'
p784
I1
sg26
I1
sg48
g49
sS'.condition'
p785
g294
sg30
F4
sS'.label'
p786
g289
sg37
S'boat horn'
p787
sS'.nDown'
p788
I1
sa(dp789
S'.stepSizes'
p790
I2
sS'.startVal'
p791
F4
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xfd?'
tRp792
sg29
I2
sg50
g51
sg31
g99
(g447
S'\xbc\xbb\xbb\xbb\xbb\xbb\xeb?'
tRp793
sg41
F292.49992513656616
sS'.minVal'
p794
F0.050000000000000003
sS'.maxVal'
p795
g275
sg38
S'left'
p796
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I2
sg34
I1
sS'.stepType'
p797
g279
sg52
g53
sg39
Vracecar
p798
sS'.staircase'
p799
g285
sS'.nUp'
p800
I1
sg26
I2
sg48
g49
sS'.condition'
p801
g294
sg30
F3.177312938897126
sS'.label'
p802
g289
sg37
S'racecar'
p803
sS'.nDown'
p804
I1
sa(dp805
S'.stepSizes'
p806
I2
sS'.startVal'
p807
F4
sg28
g128
sg40
I01
sg32
g99
(g447
S'\x9d[\xf65\xdf\x1f\x04@'
tRp808
sg29
I2
sg50
g51
sg31
g99
(g447
S'DDDDDD\xf8?'
tRp809
sg41
F302.66772794723511
sS'.minVal'
p810
F0.050000000000000003
sS'.maxVal'
p811
g244
sg38
S'up'
p812
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I3
sg34
I1
sS'.stepType'
p813
g252
sg52
g53
sg39
Vpig
p814
sS'.staircase'
p815
g258
sS'.nUp'
p816
I3
sg26
I2
sg48
g49
sS'.condition'
p817
g267
sg30
F3.177312938897126
sS'.label'
p818
g262
sg37
S'pig'
p819
sS'.nDown'
p820
I1
sa(dp821
S'.stepSizes'
p822
I2
sS'.startVal'
p823
F4
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xa4\xb2\xc4%\xbd\xed\xfe?'
tRp824
sg29
I2
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xed?'
tRp825
sg41
F311.75552892684937
sS'.minVal'
p826
F0.050000000000000003
sS'.maxVal'
p827
g244
sg38
S'up'
p828
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I4
sg34
I1
sS'.stepType'
p829
g252
sg52
g53
sg39
Vmonkeys
p830
sS'.staircase'
p831
g258
sS'.nUp'
p832
I3
sg26
I3
sg48
g49
sS'.condition'
p833
g267
sg30
F2.523829377920773
sS'.label'
p834
g262
sg37
S'monkeys'
p835
sS'.nDown'
p836
I1
sa(dp837
S'.stepSizes'
p838
I2
sS'.startVal'
p839
F4
sg28
g128
sg40
I01
sg32
g99
(g447
S'\x94\x87\xbe\xbbg\xd8\xfd?'
tRp840
sg29
I2
sg50
g51
sg31
g99
(g447
S'\xbc\xbb\xbb\xbb\xbb\xbb\xeb?'
tRp841
sg41
F322.1794171333313
sS'.minVal'
p842
F0.050000000000000003
sS'.maxVal'
p843
g275
sg38
S'right'
p844
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I5
sg34
I1
sS'.stepType'
p845
g279
sg52
g53
sg39
Vdog whining
p846
sS'.staircase'
p847
g285
sS'.nUp'
p848
I1
sg26
I3
sg48
g49
sS'.condition'
p849
g294
sg30
F2.523829377920773
sS'.label'
p850
g289
sg37
S'dog whining'
p851
sS'.nDown'
p852
I1
sa(dp853
S'.stepSizes'
p854
I2
sS'.startVal'
p855
F4
sg28
g128
sg40
I01
sg32
g99
(g447
S'6\xe4\x1d7\xdf\xaf\xff?'
tRp856
sg29
I2
sg50
g51
sg31
g99
(g447
S'333333\xf3?'
tRp857
sg41
F331.20327210426331
sS'.minVal'
p858
F0.050000000000000003
sS'.maxVal'
p859
g275
sg38
S'down'
p860
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I6
sg34
I1
sS'.stepType'
p861
g279
sg52
g53
sg39
Vcricket
p862
sS'.staircase'
p863
g285
sS'.nUp'
p864
I1
sg26
I4
sg48
g49
sS'.condition'
p865
g294
sg30
F2.004748934509089
sS'.label'
p866
g289
sg37
S'cricket'
p867
sS'.nDown'
p868
I1
sa(dp869
S'.stepSizes'
p870
I2
sS'.startVal'
p871
F4
sg28
g128
sg40
I00
sg32
g99
(g447
S'b#ewLp\x00@'
tRp872
sg29
I2
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xf1?'
tRp873
sg41
F341.05107092857361
sS'.minVal'
p874
F0.050000000000000003
sS'.maxVal'
p875
g244
sg38
S'down'
p876
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I7
sg34
I1
sS'.stepType'
p877
g252
sg52
g53
sg39
Vcow
p878
sS'.staircase'
p879
g258
sS'.nUp'
p880
I3
sg26
I4
sg48
g49
sS'.condition'
p881
g267
sg30
F2.004748934509089
sS'.label'
p882
g262
sg37
S'horse'
p883
sS'.nDown'
p884
I1
sa(dp885
S'.stepSizes'
p886
I2
sS'.startVal'
p887
F4
sg28
g296
sg40
I01
sg32
g99
(g447
S'\x9a\x84\xdf\xf0|\x0f\x01@'
tRp888
sg29
I2
sg50
g51
sg31
g99
(g447
S'""""""\xf2?'
tRp889
sg41
F350.89893698692322
sS'.minVal'
p890
F0.050000000000000003
sS'.maxVal'
p891
g244
sg38
S'left'
p892
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I8
sg34
I1
sS'.stepType'
p893
g252
sg52
g53
sg39
Vrooster
p894
sS'.staircase'
p895
g258
sS'.nUp'
p896
I3
sg26
I5
sg48
g49
sS'.condition'
p897
g267
sg30
F2.523829377920773
sS'.label'
p898
g262
sg37
S'rooster'
p899
sS'.nDown'
p900
I1
sa(dp901
S'.stepSizes'
p902
I2
sS'.startVal'
p903
F4
sg28
g128
sg40
I00
sg32
g99
(g447
S'\xd3\xd9{G\xa7\xcd\xe6?'
tRp904
sg29
I2
sg50
g51
sg31
g99
(g447
S'\x9a\x99\x99\x99\x99\x99\xa9?'
tRp905
sg41
F361.67471504211426
sS'.minVal'
p906
F0.050000000000000003
sS'.maxVal'
p907
g275
sg38
S'up'
p908
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I9
sg34
I1
sS'.stepType'
p909
g279
sg52
g53
sg39
Vslot machine
p910
sS'.staircase'
p911
g285
sS'.nUp'
p912
I1
sg26
I5
sg48
g49
sS'.condition'
p913
g294
sg30
F1.5924286822139888
sS'.label'
p914
g289
sg37
S'cymbal'
p915
sS'.nDown'
p916
I1
sa(dp917
S'.stepSizes'
p918
I4
sS'.startVal'
p919
F1
sg28
g446
sg40
I00
sg32
g99
(g447
S'`tW\xdd\xbf\xd1\xf8?'
tRp920
sg29
I4
sg50
g51
sg31
g99
(g447
S'ffffff\xd6?'
tRp921
sg41
F402.96204710006714
sS'.minVal'
p922
F0.050000000000000003
sS'.maxVal'
p923
g309
sg38
S'up'
p924
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I0
sg34
I1
sS'.stepType'
p925
g317
sg52
g53
sg39
Vsent
p926
sS'.staircase'
p927
g323
sS'.nUp'
p928
I3
sg26
I1
sg48
g49
sS'.condition'
p929
g332
sg30
F1
sS'.label'
p930
g327
sg37
S'tent'
p931
sS'.nDown'
p932
I1
sa(dp933
S'.stepSizes'
p934
I4
sS'.startVal'
p935
F1
sg28
g446
sg40
I00
sg32
g99
(g447
S'Z\xd1\x0c2\x96|\xf7?'
tRp936
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xcd?'
tRp937
sg41
F413.64996910095215
sS'.minVal'
p938
F0.050000000000000003
sS'.maxVal'
p939
g340
sg38
S'down'
p940
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I1
sg34
I1
sS'.stepType'
p941
g344
sg52
g53
sg39
Vtent
p942
sS'.staircase'
p943
g350
sS'.nUp'
p944
I1
sg26
I1
sg48
g49
sS'.condition'
p945
g359
sg30
F1
sS'.label'
p946
g354
sg37
S'sent'
p947
sS'.nDown'
p948
I1
sa(dp949
S'.stepSizes'
p950
I4
sS'.startVal'
p951
F1
sg28
g296
sg40
I01
sg32
g99
(g447
S'Xt\xb7\xe7&\xf1\x00@'
tRp952
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xcc\xcc\xcc\xcc\xcc\xcc\xf0?'
tRp953
sg41
F422.88974404335022
sS'.minVal'
p954
F0.050000000000000003
sS'.maxVal'
p955
g309
sg38
S'right'
p956
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I2
sg34
I1
sS'.stepType'
p957
g317
sg52
g53
sg39
Vwore
p958
sS'.staircase'
p959
g323
sS'.nUp'
p960
I3
sg26
I2
sg48
g49
sS'.condition'
p961
g332
sg30
F1.5848931924611136
sS'.label'
p962
g327
sg37
S'wore'
p963
sS'.nDown'
p964
I1
sa(dp965
S'.stepSizes'
p966
I4
sS'.startVal'
p967
F1
sg28
g296
sg40
I00
sg32
g99
(g447
S'\\z\xd9k\xbc$\x06@'
tRp968
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xf8?'
tRp969
sg41
F432.05760097503662
sS'.minVal'
p970
F0.050000000000000003
sS'.maxVal'
p971
g340
sg38
S'down'
p972
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I3
sg34
I1
sS'.stepType'
p973
g344
sg52
g53
sg39
Vbin
p974
sS'.staircase'
p975
g350
sS'.nUp'
p976
I1
sg26
I2
sg48
g49
sS'.condition'
p977
g359
sg30
F1.5848931924611136
sS'.label'
p978
g354
sg37
S'pin'
p979
sS'.nDown'
p980
I1
sa(dp981
S'.stepSizes'
p982
I4
sS'.startVal'
p983
F1
sg28
g128
sg40
I00
sg32
g99
(g447
S'\x1d\x84\xb2\xd1M\xf2\x02@'
tRp984
sg29
I4
sg50
g51
sg31
g99
(g447
S'xwwwww\xe7?'
tRp985
sg41
F443.29733300209045
sS'.minVal'
p986
F0.050000000000000003
sS'.maxVal'
p987
g309
sg38
S'right'
p988
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I4
sg34
I1
sS'.stepType'
p989
g317
sg52
g53
sg39
Vverve
p990
sS'.staircase'
p991
g323
sS'.nUp'
p992
I3
sg26
I3
sg48
g49
sS'.condition'
p993
g332
sg30
F1
sS'.label'
p994
g327
sg37
S'verge'
p995
sS'.nDown'
p996
I1
sa(dp997
S'.stepSizes'
p998
I4
sS'.startVal'
p999
F1
sg28
g296
sg40
I01
sg32
g99
(g447
S'\xeei\x14,\x87F\x02@'
tRp1000
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xef\xee\xee\xee\xee\xee\xf2?'
tRp1001
sg41
F452.32120299339294
sS'.minVal'
p1002
F0.050000000000000003
sS'.maxVal'
p1003
g340
sg38
S'right'
p1004
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I5
sg34
I1
sS'.stepType'
p1005
g344
sg52
g53
sg39
Vbee
p1006
sS'.staircase'
p1007
g350
sS'.nUp'
p1008
I1
sg26
I3
sg48
g49
sS'.condition'
p1009
g359
sg30
F2.5118864315095806
sS'.label'
p1010
g354
sg37
S'bee'
p1011
sS'.nDown'
p1012
I1
sa(dp1013
S'.stepSizes'
p1014
I4
sS'.startVal'
p1015
F1
sg28
g128
sg40
I01
sg32
g99
(g447
S'\x9au1\x80#\x14\x03@'
tRp1016
sg29
I4
sg50
g51
sg31
g99
(g447
S'EDDDDD\xec?'
tRp1017
sg41
F461.73696804046631
sS'.minVal'
p1018
F0.050000000000000003
sS'.maxVal'
p1019
g340
sg38
S'left'
p1020
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I6
sg34
I1
sS'.stepType'
p1021
g344
sg52
g53
sg39
Vshow
p1022
sS'.staircase'
p1023
g350
sS'.nUp'
p1024
I1
sg26
I4
sg48
g49
sS'.condition'
p1025
g359
sg30
F1.5848931924611136
sS'.label'
p1026
g354
sg37
S'show'
p1027
sS'.nDown'
p1028
I1
sa(dp1029
S'.stepSizes'
p1030
I4
sS'.startVal'
p1031
F1
sg28
g128
sg40
I01
sg32
g99
(g447
S'\x00\x80\x87ffF\x06@'
tRp1032
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xfc?'
tRp1033
sg41
F472.16078591346741
sS'.minVal'
p1034
F0.050000000000000003
sS'.maxVal'
p1035
g309
sg38
S'right'
p1036
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I7
sg34
I1
sS'.stepType'
p1037
g317
sg52
g53
sg39
Vterse
p1038
sS'.staircase'
p1039
g323
sS'.nUp'
p1040
I3
sg26
I4
sg48
g49
sS'.condition'
p1041
g332
sg30
F1
sS'.label'
p1042
g327
sg37
S'terse'
p1043
sS'.nDown'
p1044
I1
sa(dp1045
S'.stepSizes'
p1046
I4
sS'.startVal'
p1047
F1
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xd2H\x84\xa9\r\xf4\xfe?'
tRp1048
sg29
I4
sg50
g51
sg31
g99
(g447
S'gfffff\xe6?'
tRp1049
sg41
F482.5527241230011
sS'.minVal'
p1050
F0.050000000000000003
sS'.maxVal'
p1051
g340
sg38
S'down'
p1052
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I8
sg34
I1
sS'.stepType'
p1053
g344
sg52
g53
sg39
Vbore
p1054
sS'.staircase'
p1055
g350
sS'.nUp'
p1056
I1
sg26
I5
sg48
g49
sS'.condition'
p1057
g359
sg30
F1
sS'.label'
p1058
g354
sg37
S'bore'
p1059
sS'.nDown'
p1060
I1
sa(dp1061
S'.stepSizes'
p1062
I4
sS'.startVal'
p1063
F1
sg28
g128
sg40
I01
sg32
g99
(g447
S'R\xdc\xcd\x10\x02\x8b\x00@'
tRp1064
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xbc\xbb\xbb\xbb\xbb\xbb\xeb?'
tRp1065
sg41
F492.36065912246704
sS'.minVal'
p1066
F0.050000000000000003
sS'.maxVal'
p1067
g309
sg38
S'down'
p1068
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I9
sg34
I1
sS'.stepType'
p1069
g317
sg52
g53
sg39
Vframe
p1070
sS'.staircase'
p1071
g323
sS'.nUp'
p1072
I3
sg26
I5
sg48
g49
sS'.condition'
p1073
g332
sg30
F0.63095734448019325
sS'.label'
p1074
g327
sg37
S'frame'
p1075
sS'.nDown'
p1076
I1
sa(dp1077
S'.stepSizes'
p1078
I4
sS'.startVal'
p1079
F2
sg28
g296
sg40
I01
sg32
g99
(g447
S'FO\xa8\xb8I\x8c\xf8?'
tRp1080
sg29
I4
sg50
g51
sg31
g99
(g447
S'EDDDDD\xe4?'
tRp1081
sg41
F502.50440096855164
sS'.minVal'
p1082
F0.050000000000000003
sS'.maxVal'
p1083
g140
sg38
S'right'
p1084
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I10
sg34
I1
sS'.stepType'
p1085
g144
sg52
g53
sg39
Vdrool
p1086
sS'.staircase'
p1087
g150
sS'.nUp'
p1088
I1
sg26
I6
sg48
g49
sS'.condition'
p1089
g159
sg30
F3.1697863849222272
sS'.label'
p1090
g154
sg37
S'drool'
p1091
sS'.nDown'
p1092
I1
sa(dp1093
S'.stepSizes'
p1094
I4
sS'.startVal'
p1095
F2
sg28
g296
sg40
I01
sg32
g99
(g447
S'/.\xdfYq\x16\xf9?'
tRp1096
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x11\x11\x11\x11\x11\x11\xd1?'
tRp1097
sg41
F512.52030205726624
sS'.minVal'
p1098
F0.050000000000000003
sS'.maxVal'
p1099
g88
sg38
S'right'
p1100
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I11
sg34
I1
sS'.stepType'
p1101
g107
sg52
g53
sg39
Vslide
p1102
sS'.staircase'
p1103
g114
sS'.nUp'
p1104
I3
sg26
I6
sg48
g49
sS'.condition'
p1105
g123
sg30
F1.2619146889603865
sS'.label'
p1106
g118
sg37
S'slide'
p1107
sS'.nDown'
p1108
I1
sa(dp1109
S'.stepSizes'
p1110
I4
sS'.startVal'
p1111
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'\x96 \x12UF\xcf\x02@'
tRp1112
sg29
I4
sg50
g51
sg31
g99
(g447
S'ffffff\xf2?'
tRp1113
sg41
F522.48807597160339
sS'.minVal'
p1114
F0.050000000000000003
sS'.maxVal'
p1115
g88
sg38
S'up'
p1116
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I12
sg34
I1
sS'.stepType'
p1117
g107
sg52
g53
sg39
Vcove
p1118
sS'.staircase'
p1119
g114
sS'.nUp'
p1120
I3
sg26
I7
sg48
g49
sS'.condition'
p1121
g123
sg30
F0.79621434110699441
sS'.label'
p1122
g118
sg37
S'code'
p1123
sS'.nDown'
p1124
I1
sa(dp1125
S'.stepSizes'
p1126
I4
sS'.startVal'
p1127
F2
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xcf\x8a(;m\xe0\x01@'
tRp1128
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xf0?'
tRp1129
sg41
F531.73587012290955
sS'.minVal'
p1130
F0.050000000000000003
sS'.maxVal'
p1131
g140
sg38
S'up'
p1132
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I13
sg34
I1
sS'.stepType'
p1133
g144
sg52
g53
sg39
Vgold
p1134
sS'.staircase'
p1135
g150
sS'.nUp'
p1136
I1
sg26
I7
sg48
g49
sS'.condition'
p1137
g159
sg30
F2
sS'.label'
p1138
g154
sg37
S'gold'
p1139
sS'.nDown'
p1140
I1
sa(dp1141
S'.stepSizes'
p1142
I4
sS'.startVal'
p1143
F2
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xaa*2\x11\x11\xf1\x02@'
tRp1144
sg29
I4
sg50
g51
sg31
g99
(g447
S'UUUUUU\xf5?'
tRp1145
sg41
F542.22370409965515
sS'.minVal'
p1146
F0.050000000000000003
sS'.maxVal'
p1147
g88
sg38
S'right'
p1148
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I14
sg34
I1
sS'.stepType'
p1149
g107
sg52
g53
sg39
Vmug
p1150
sS'.staircase'
p1151
g114
sS'.nUp'
p1152
I3
sg26
I8
sg48
g49
sS'.condition'
p1153
g123
sg30
F0.79621434110699441
sS'.label'
p1154
g118
sg37
S'mug'
p1155
sS'.nDown'
p1156
I1
sa(dp1157
S'.stepSizes'
p1158
I4
sS'.startVal'
p1159
F2
sg28
g128
sg40
I01
sg32
g99
(g447
S'\x90\xa3\t\x84\xb3\xcf\x02@'
tRp1160
sg29
I4
sg50
g51
sg31
g99
(g447
S'gfffff\xee?'
tRp1161
sg41
F552.3276059627533
sS'.minVal'
p1162
F0.050000000000000003
sS'.maxVal'
p1163
g140
sg38
S'up'
p1164
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I15
sg34
I1
sS'.stepType'
p1165
g144
sg52
g53
sg39
Vguilt
p1166
sS'.staircase'
p1167
g150
sS'.nUp'
p1168
I1
sg26
I8
sg48
g49
sS'.condition'
p1169
g159
sg30
F1.2619146889603865
sS'.label'
p1170
g154
sg37
S'guilt'
p1171
sS'.nDown'
p1172
I1
sa(dp1173
S'.stepSizes'
p1174
I4
sS'.startVal'
p1175
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'\xe9>\xe5\xea`\x9e\xf5?'
tRp1176
sg29
I4
sg50
g51
sg31
g99
(g447
S'wwwwww\xc7?'
tRp1177
sg41
F563.26327705383301
sS'.minVal'
p1178
F0.050000000000000003
sS'.maxVal'
p1179
g140
sg38
S'up'
p1180
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I16
sg34
I1
sS'.stepType'
p1181
g144
sg52
g53
sg39
Vrest
p1182
sS'.staircase'
p1183
g150
sS'.nUp'
p1184
I1
sg26
I9
sg48
g49
sS'.condition'
p1185
g159
sg30
F0.79621434110699441
sS'.label'
p1186
g154
sg37
S'vest'
p1187
sS'.nDown'
p1188
I1
sa(dp1189
S'.stepSizes'
p1190
I4
sS'.startVal'
p1191
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'0l*O\xf0\xc0\xfb?'
tRp1192
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xdd?'
tRp1193
sg41
F573.43908500671387
sS'.minVal'
p1194
F0.050000000000000003
sS'.maxVal'
p1195
g88
sg38
S'right'
p1196
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I17
sg34
I1
sS'.stepType'
p1197
g107
sg52
g53
sg39
Vchose
p1198
sS'.staircase'
p1199
g114
sS'.nUp'
p1200
I3
sg26
I9
sg48
g49
sS'.condition'
p1201
g123
sg30
F0.50237728630191592
sS'.label'
p1202
g118
sg37
S'froze'
p1203
sS'.nDown'
p1204
I1
sa(dp1205
S'.stepSizes'
p1206
I4
sS'.startVal'
p1207
F2
sg28
g296
sg40
I01
sg32
g99
(g447
S'\x16\x8d\xc8\xedQ8\xfb?'
tRp1208
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xdd?'
tRp1209
sg41
F583.63899707794189
sS'.minVal'
p1210
F0.050000000000000003
sS'.maxVal'
p1211
g140
sg38
S'left'
p1212
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I18
sg34
I1
sS'.stepType'
p1213
g144
sg52
g53
sg39
Vthink
p1214
sS'.staircase'
p1215
g150
sS'.nUp'
p1216
I1
sg26
I10
sg48
g49
sS'.condition'
p1217
g159
sg30
F1.2619146889603865
sS'.label'
p1218
g154
sg37
S'think'
p1219
sS'.nDown'
p1220
I1
sa(dp1221
S'.stepSizes'
p1222
I4
sS'.startVal'
p1223
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'\x00\x00\x0f\xcd\xcc\x8c\xf8?'
tRp1224
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xe0?'
tRp1225
sg41
F594.08701610565186
sS'.minVal'
p1226
F0.050000000000000003
sS'.maxVal'
p1227
g88
sg38
S'up'
p1228
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I19
sg34
I1
sS'.stepType'
p1229
g107
sg52
g53
sg39
Vwick
p1230
sS'.staircase'
p1231
g114
sS'.nUp'
p1232
I3
sg26
I10
sg48
g49
sS'.condition'
p1233
g123
sg30
F0.50237728630191592
sS'.label'
p1234
g118
sg37
S'tick'
p1235
sS'.nDown'
p1236
I1
sa(dp1237
S'.stepSizes'
p1238
I4
sS'.startVal'
p1239
F2
sg28
g296
sg40
I00
sg32
g99
(g447
S'\x02\xbfFy?5\x03@'
tRp1240
sg29
I4
sg50
g51
sg31
g99
(g447
S'ffffff\xf6?'
tRp1241
sg41
F606.08665013313293
sS'.minVal'
p1242
F0.050000000000000003
sS'.maxVal'
p1243
g211
sg38
S'left'
p1244
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I10
sg34
I1
sS'.stepType'
p1245
g215
sg52
g53
sg39
Voro
p1246
sS'.staircase'
p1247
g221
sS'.nUp'
p1248
I1
sg26
I6
sg48
g49
sS'.condition'
p1249
g230
sg30
F1.2619146889603865
sS'.label'
p1250
g225
sg37
S'oho'
p1251
sS'.nDown'
p1252
I1
sa(dp1253
S'.stepSizes'
p1254
I4
sS'.startVal'
p1255
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'\xd6L\x8d|=j\xf6?'
tRp1256
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xdd?'
tRp1257
sg41
F616.27844595909119
sS'.minVal'
p1258
F0.050000000000000003
sS'.maxVal'
p1259
g180
sg38
S'right'
p1260
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I11
sg34
I1
sS'.stepType'
p1261
g188
sg52
g53
sg39
Vara
p1262
sS'.staircase'
p1263
g194
sS'.nUp'
p1264
I3
sg26
I6
sg48
g49
sS'.condition'
p1265
g203
sg30
F0.50237728630191592
sS'.label'
p1266
g198
sg37
S'ana'
p1267
sS'.nDown'
p1268
I1
sa(dp1269
S'.stepSizes'
p1270
I4
sS'.startVal'
p1271
F2
sg28
g296
sg40
I01
sg32
g99
(g447
S"'b\x02z\xda\xf0\x04@"
tRp1272
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xef\xee\xee\xee\xee\xee\xfa?'
tRp1273
sg41
F625.99818301200867
sS'.minVal'
p1274
F0.050000000000000003
sS'.maxVal'
p1275
g211
sg38
S'up'
p1276
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I12
sg34
I1
sS'.stepType'
p1277
g215
sg52
g53
sg39
Vunu
p1278
sS'.staircase'
p1279
g221
sS'.nUp'
p1280
I1
sg26
I7
sg48
g49
sS'.condition'
p1281
g230
sg30
F2
sS'.label'
p1282
g225
sg37
S'unu'
p1283
sS'.nDown'
p1284
I1
sa(dp1285
S'.stepSizes'
p1286
I4
sS'.startVal'
p1287
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'\xa8\xdf\x9e\xf9\x8b%\xfe?'
tRp1288
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xcc\xcc\xcc\xcc\xcc\xcc\xf0?'
tRp1289
sg41
F636.57416796684265
sS'.minVal'
p1290
F0.050000000000000003
sS'.maxVal'
p1291
g180
sg38
S'left'
p1292
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I13
sg34
I1
sS'.stepType'
p1293
g188
sg52
g53
sg39
Veche
p1294
sS'.staircase'
p1295
g194
sS'.nUp'
p1296
I3
sg26
I7
sg48
g49
sS'.condition'
p1297
g203
sg30
F0.50237728630191592
sS'.label'
p1298
g198
sg37
S'ewe'
p1299
sS'.nDown'
p1300
I1
sa(dp1301
S'.stepSizes'
p1302
I4
sS'.startVal'
p1303
F2
sg28
g128
sg40
I00
sg32
g99
(g447
S'\x18\xb4\x13A\nW\x01@'
tRp1304
sg29
I4
sg50
g51
sg31
g99
(g447
S'UUUUUU\xf5?'
tRp1305
sg41
F646.08591103553772
sS'.minVal'
p1306
F0.050000000000000003
sS'.maxVal'
p1307
g180
sg38
S'up'
p1308
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I14
sg34
I1
sS'.stepType'
p1309
g188
sg52
g53
sg39
Veye
p1310
sS'.staircase'
p1311
g194
sS'.nUp'
p1312
I3
sg26
I8
sg48
g49
sS'.condition'
p1313
g203
sg30
F0.50237728630191592
sS'.label'
p1314
g198
sg37
S'ese'
p1315
sS'.nDown'
p1316
I1
sa(dp1317
S'.stepSizes'
p1318
I4
sS'.startVal'
p1319
F2
sg28
g128
sg40
I01
sg32
g99
(g447
S'>m{s\xcbz\xf3?'
tRp1320
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xab\xaa\xaa\xaa\xaa\xaa\xda?'
tRp1321
sg41
F656.08573913574219
sS'.minVal'
p1322
F0.050000000000000003
sS'.maxVal'
p1323
g211
sg38
S'up'
p1324
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I15
sg34
I1
sS'.stepType'
p1325
g215
sg52
g53
sg39
Vili
p1326
sS'.staircase'
p1327
g221
sS'.nUp'
p1328
I1
sg26
I8
sg48
g49
sS'.condition'
p1329
g230
sg30
F1.2619146889603865
sS'.label'
p1330
g225
sg37
S'ili'
p1331
sS'.nDown'
p1332
I1
sa(dp1333
S'.stepSizes'
p1334
I4
sS'.startVal'
p1335
F2
sg28
g128
sg40
I01
sg32
g99
(g447
S'xw\x86DD\x04\xf4?'
tRp1336
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xbc\xbb\xbb\xbb\xbb\xbb\xcb?'
tRp1337
sg41
F665.31756591796875
sS'.minVal'
p1338
F0.050000000000000003
sS'.maxVal'
p1339
g211
sg38
S'down'
p1340
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I16
sg34
I1
sS'.stepType'
p1341
g215
sg52
g53
sg39
Vuku
p1342
sS'.staircase'
p1343
g221
sS'.nUp'
p1344
I1
sg26
I9
sg48
g49
sS'.condition'
p1345
g230
sg30
F0.79621434110699441
sS'.label'
p1346
g225
sg37
S'uku'
p1347
sS'.nDown'
p1348
I1
sa(dp1349
S'.stepSizes'
p1350
I4
sS'.startVal'
p1351
F2
sg28
g296
sg40
I01
sg32
g99
(g447
S'I\x84$\x9c\xfc\x12\x03@'
tRp1352
sg29
I4
sg50
g51
sg31
g99
(g447
S'333333\xf7?'
tRp1353
sg41
F675.43746495246887
sS'.minVal'
p1354
F0.050000000000000003
sS'.maxVal'
p1355
g180
sg38
S'right'
p1356
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I17
sg34
I1
sS'.stepType'
p1357
g188
sg52
g53
sg39
Volo
p1358
sS'.staircase'
p1359
g194
sS'.nUp'
p1360
I3
sg26
I9
sg48
g49
sS'.condition'
p1361
g203
sg30
F0.79621434110699441
sS'.label'
p1362
g198
sg37
S'olo'
p1363
sS'.nDown'
p1364
I1
sa(dp1365
S'.stepSizes'
p1366
I4
sS'.startVal'
p1367
F2
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xbez\x025\xfb\xf0\x04@'
tRp1368
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xf9?'
tRp1369
sg41
F686.03739500045776
sS'.minVal'
p1370
F0.050000000000000003
sS'.maxVal'
p1371
g180
sg38
S'right'
p1372
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I18
sg34
I1
sS'.stepType'
p1373
g188
sg52
g53
sg39
Vawa
p1374
sS'.staircase'
p1375
g194
sS'.nUp'
p1376
I3
sg26
I10
sg48
g49
sS'.condition'
p1377
g203
sg30
F0.50237728630191592
sS'.label'
p1378
g198
sg37
S'awa'
p1379
sS'.nDown'
p1380
I1
sa(dp1381
S'.stepSizes'
p1382
I4
sS'.startVal'
p1383
F2
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xf6t\xcd\x8a\x16i\x00@'
tRp1384
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xe8?'
tRp1385
sg41
F697.46104001998901
sS'.minVal'
p1386
F0.050000000000000003
sS'.maxVal'
p1387
g211
sg38
S'down'
p1388
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I19
sg34
I1
sS'.stepType'
p1389
g215
sg52
g53
sg39
Vulu
p1390
sS'.staircase'
p1391
g221
sS'.nUp'
p1392
I1
sg26
I10
sg48
g49
sS'.condition'
p1393
g230
sg30
F0.50237728630191592
sS'.label'
p1394
g225
sg37
S'ulu'
p1395
sS'.nDown'
p1396
I1
sa(dp1397
S'.stepSizes'
p1398
I2
sS'.startVal'
p1399
F4
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xf5\xf6\x82\xd1Mr\x05@'
tRp1400
sg29
I2
sg50
g51
sg31
g99
(g447
S'\xef\xee\xee\xee\xee\xee\xfe?'
tRp1401
sg41
F738.53235507011414
sS'.minVal'
p1402
F0.050000000000000003
sS'.maxVal'
p1403
g244
sg38
S'left'
p1404
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I10
sg34
I1
sS'.stepType'
p1405
g252
sg52
g53
sg39
Vcoin dropping
p1406
sS'.staircase'
p1407
g258
sS'.nUp'
p1408
I3
sg26
I6
sg48
g49
sS'.condition'
p1409
g267
sg30
F2.004748934509089
sS'.label'
p1410
g262
sg37
S'coin dropping'
p1411
sS'.nDown'
p1412
I1
sa(dp1413
S'.stepSizes'
p1414
I2
sS'.startVal'
p1415
F4
sg28
g296
sg40
I00
sg32
g99
(g447
S'u\x1a#\x996\xf0\xf6?'
tRp1416
sg29
I2
sg50
g51
sg31
g99
(g447
S'\xbc\xbb\xbb\xbb\xbb\xbb\xdb?'
tRp1417
sg41
F749.06839609146118
sS'.minVal'
p1418
F0.050000000000000003
sS'.maxVal'
p1419
g275
sg38
S'down'
p1420
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I11
sg34
I1
sS'.stepType'
p1421
g279
sg52
g53
sg39
Vcash register
p1422
sS'.staircase'
p1423
g285
sS'.nUp'
p1424
I1
sg26
I6
sg48
g49
sS'.condition'
p1425
g294
sg30
F2.004748934509089
sS'.label'
p1426
g289
sg37
S'wind chimes'
p1427
sS'.nDown'
p1428
I1
sa(dp1429
S'.stepSizes'
p1430
I2
sS'.startVal'
p1431
F4
sg28
g296
sg40
I01
sg32
g99
(g447
S'L\xa4\r*\xf9\x05\xf4?'
tRp1432
sg29
I2
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xd0?'
tRp1433
sg41
F757.96396112442017
sS'.minVal'
p1434
F0.050000000000000003
sS'.maxVal'
p1435
g275
sg38
S'left'
p1436
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I12
sg34
I1
sS'.stepType'
p1437
g279
sg52
g53
sg39
Vtambourine
p1438
sS'.staircase'
p1439
g285
sS'.nUp'
p1440
I1
sg26
I7
sg48
g49
sS'.condition'
p1441
g294
sg30
F2.523829377920773
sS'.label'
p1442
g289
sg37
S'tambourine'
p1443
sS'.nDown'
p1444
I1
sa(dp1445
S'.stepSizes'
p1446
I2
sS'.startVal'
p1447
F4
sg28
g128
sg40
I00
sg32
g99
(g447
S'\xcfcne\xd4\xff\xef?'
tRp1448
sg29
I2
sg50
g51
sg31
g99
(g447
S'\x11\x11\x11\x11\x11\x11\xa1?'
tRp1449
sg41
F768.0758900642395
sS'.minVal'
p1450
F0.050000000000000003
sS'.maxVal'
p1451
g244
sg38
S'right'
p1452
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I13
sg34
I1
sS'.stepType'
p1453
g252
sg52
g53
sg39
Vtruck backing up
p1454
sS'.staircase'
p1455
g258
sS'.nUp'
p1456
I3
sg26
I7
sg48
g49
sS'.condition'
p1457
g267
sg30
F1.5924286822139888
sS'.label'
p1458
g262
sg37
S'fireworks'
p1459
sS'.nDown'
p1460
I1
sa(dp1461
S'.stepSizes'
p1462
I2
sS'.startVal'
p1463
F4
sg28
g128
sg40
I01
sg32
g99
(g447
S'\x16\x18MY\x0e\x8d\xf3?'
tRp1464
sg29
I2
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xd0?'
tRp1465
sg41
F779.05970406532288
sS'.minVal'
p1466
F0.050000000000000003
sS'.maxVal'
p1467
g275
sg38
S'right'
p1468
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I14
sg34
I1
sS'.stepType'
p1469
g279
sg52
g53
sg39
Vcar door
p1470
sS'.staircase'
p1471
g285
sS'.nUp'
p1472
I1
sg26
I8
sg48
g49
sS'.condition'
p1473
g294
sg30
F2.004748934509089
sS'.label'
p1474
g289
sg37
S'car door'
p1475
sS'.nDown'
p1476
I1
sa(dp1477
S'.stepSizes'
p1478
I2
sS'.startVal'
p1479
F4
sg28
g128
sg40
I00
sg32
g99
(g447
S'(I\x87\x872\xfa\xff?'
tRp1480
sg29
I2
sg50
g51
sg31
g99
(g447
S'\x99\x99\x99\x99\x99\x99\xf1?'
tRp1481
sg41
F789.72356605529785
sS'.minVal'
p1482
F0.050000000000000003
sS'.maxVal'
p1483
g244
sg38
S'up'
p1484
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I15
sg34
I1
sS'.stepType'
p1485
g252
sg52
g53
sg39
Vthunder
p1486
sS'.staircase'
p1487
g258
sS'.nUp'
p1488
I3
sg26
I8
sg48
g49
sS'.condition'
p1489
g267
sg30
F1.5924286822139888
sS'.label'
p1490
g262
sg37
S'elephant'
p1491
sS'.nDown'
p1492
I1
sa(dp1493
S'.stepSizes'
p1494
I2
sS'.startVal'
p1495
F4
sg28
g128
sg40
I00
sg32
g99
(g447
S'xF\r\n\xf3T\x01@'
tRp1496
sg29
I2
sg50
g51
sg31
g99
(g447
S'\xaa\xaa\xaa\xaa\xaa\xaa\xf2?'
tRp1497
sg41
F799.73932695388794
sS'.minVal'
p1498
F0.050000000000000003
sS'.maxVal'
p1499
g244
sg38
S'right'
p1500
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I16
sg34
I1
sS'.stepType'
p1501
g252
sg52
g53
sg39
Vracecar
p1502
sS'.staircase'
p1503
g258
sS'.nUp'
p1504
I3
sg26
I9
sg48
g49
sS'.condition'
p1505
g267
sg30
F1.5924286822139888
sS'.label'
p1506
g262
sg37
S'train whistle'
p1507
sS'.nDown'
p1508
I1
sa(dp1509
S'.stepSizes'
p1510
I2
sS'.startVal'
p1511
F4
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xc2\xc0T\x07\x9d\xe6\x01@'
tRp1512
sg29
I2
sg50
g51
sg31
g99
(g447
S'DDDDDD\xf4?'
tRp1513
sg41
F809.01913595199585
sS'.minVal'
p1514
F0.050000000000000003
sS'.maxVal'
p1515
g275
sg38
S'up'
p1516
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I17
sg34
I1
sS'.stepType'
p1517
g279
sg52
g53
sg39
Vduck
p1518
sS'.staircase'
p1519
g285
sS'.nUp'
p1520
I1
sg26
I9
sg48
g49
sS'.condition'
p1521
g294
sg30
F1.5924286822139888
sS'.label'
p1522
g289
sg37
S'duck'
p1523
sS'.nDown'
p1524
I1
sa(dp1525
S'.stepSizes'
p1526
I2
sS'.startVal'
p1527
F4
sg28
g128
sg40
I00
sg32
g99
(g447
S'\xf6\xfa(0\x96\x8c\x03@'
tRp1528
sg29
I2
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xfc?'
tRp1529
sg41
F820.03486895561218
sS'.minVal'
p1530
F0.050000000000000003
sS'.maxVal'
p1531
g275
sg38
S'up'
p1532
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I18
sg34
I1
sS'.stepType'
p1533
g279
sg52
g53
sg39
Vdoor opening
p1534
sS'.staircase'
p1535
g285
sS'.nUp'
p1536
I1
sg26
I10
sg48
g49
sS'.condition'
p1537
g294
sg30
F1.2649110640673515
sS'.label'
p1538
g289
sg37
S'glass breaking'
p1539
sS'.nDown'
p1540
I1
sa(dp1541
S'.stepSizes'
p1542
I2
sS'.startVal'
p1543
F4
sg28
g296
sg40
I01
sg32
g99
(g447
S'\x9d\xc6\x9df\x91-\xf5?'
tRp1544
sg29
I2
sg50
g51
sg31
g99
(g447
S'\x88\x88\x88\x88\x88\x88\xd8?'
tRp1545
sg41
F830.57079195976257
sS'.minVal'
p1546
F0.050000000000000003
sS'.maxVal'
p1547
g244
sg38
S'right'
p1548
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I19
sg34
I1
sS'.stepType'
p1549
g252
sg52
g53
sg39
Vrock splashing into water
p1550
sS'.staircase'
p1551
g258
sS'.nUp'
p1552
I3
sg26
I10
sg48
g49
sS'.condition'
p1553
g267
sg30
F2.004748934509089
sS'.label'
p1554
g262
sg37
S'rock splashing into water'
p1555
sS'.nDown'
p1556
I1
sa(dp1557
S'.stepSizes'
p1558
I4
sS'.startVal'
p1559
F1
sg28
g128
sg40
I01
sg32
g99
(g447
S'/.\xdfYq\x16\xf5?'
tRp1560
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x11\x11\x11\x11\x11\x11\x91?'
tRp1561
sg41
F842.12256598472595
sS'.minVal'
p1562
F0.050000000000000003
sS'.maxVal'
p1563
g309
sg38
S'up'
p1564
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I10
sg34
I1
sS'.stepType'
p1565
g317
sg52
g53
sg39
Vtrace
p1566
sS'.staircase'
p1567
g323
sS'.nUp'
p1568
I3
sg26
I6
sg48
g49
sS'.condition'
p1569
g332
sg30
F0.3981071705534972
sS'.label'
p1570
g327
sg37
S'trace'
p1571
sS'.nDown'
p1572
I1
sa(dp1573
S'.stepSizes'
p1574
I4
sS'.startVal'
p1575
F1
sg28
g128
sg40
I01
sg32
g99
(g447
S"\x186\x95'x\xe0\x05@"
tRp1576
sg29
I4
sg50
g51
sg31
g99
(g447
S'wwwwww\xf7?'
tRp1577
sg41
F852.08237409591675
sS'.minVal'
p1578
F0.050000000000000003
sS'.maxVal'
p1579
g340
sg38
S'up'
p1580
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I11
sg34
I1
sS'.stepType'
p1581
g344
sg52
g53
sg39
Vwine
p1582
sS'.staircase'
p1583
g350
sS'.nUp'
p1584
I1
sg26
I6
sg48
g49
sS'.condition'
p1585
g359
sg30
F0.63095734448019325
sS'.label'
p1586
g354
sg37
S'wine'
p1587
sS'.nDown'
p1588
I1
sa(dp1589
S'.stepSizes'
p1590
I4
sS'.startVal'
p1591
F1
sg28
g128
sg40
I00
sg32
g99
(g447
S'f\xe6\xed\xcc\xcc\xac\x06@'
tRp1592
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xcc\xcc\xcc\xcc\xcc\xcc\xfc?'
tRp1593
sg41
F863.78627610206604
sS'.minVal'
p1594
F0.050000000000000003
sS'.maxVal'
p1595
g309
sg38
S'left'
p1596
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I12
sg34
I1
sS'.stepType'
p1597
g317
sg52
g53
sg39
Vcare
p1598
sS'.staircase'
p1599
g323
sS'.nUp'
p1600
I3
sg26
I7
sg48
g49
sS'.condition'
p1601
g332
sg30
F0.25118864315095796
sS'.label'
p1602
g327
sg37
S'tear'
p1603
sS'.nDown'
p1604
I1
sa(dp1605
S'.stepSizes'
p1606
I4
sS'.startVal'
p1607
F1
sg28
g128
sg40
I01
sg32
g99
(g447
S'D\xd2\xb4\xbf\x02\x04\xf0?'
tRp1608
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x11\x11\x11\x11\x11\x11\xa1?'
tRp1609
sg41
F873.56203508377075
sS'.minVal'
p1610
F0.050000000000000003
sS'.maxVal'
p1611
g340
sg38
S'up'
p1612
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I13
sg34
I1
sS'.stepType'
p1613
g344
sg52
g53
sg39
Vden
p1614
sS'.staircase'
p1615
g350
sS'.nUp'
p1616
I1
sg26
I7
sg48
g49
sS'.condition'
p1617
g359
sg30
F0.3981071705534972
sS'.label'
p1618
g354
sg37
S'den'
p1619
sS'.nDown'
p1620
I1
sa(dp1621
S'.stepSizes'
p1622
I4
sS'.startVal'
p1623
F1
sg28
g128
sg40
I00
sg32
g99
(g447
S'\x9a\x99\xa8ff&\xfe?'
tRp1624
sg29
I4
sg50
g51
sg31
g99
(g447
S'433333\xeb?'
tRp1625
sg41
F883.88189005851746
sS'.minVal'
p1626
F0.050000000000000003
sS'.maxVal'
p1627
g309
sg38
S'down'
p1628
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I14
sg34
I1
sS'.stepType'
p1629
g317
sg52
g53
sg39
Vstow
p1630
sS'.staircase'
p1631
g323
sS'.nUp'
p1632
I3
sg26
I8
sg48
g49
sS'.condition'
p1633
g332
sg30
F0.25118864315095796
sS'.label'
p1634
g327
sg37
S'snow'
p1635
sS'.nDown'
p1636
I1
sa(dp1637
S'.stepSizes'
p1638
I4
sS'.startVal'
p1639
F1
sg28
g128
sg40
I00
sg32
g99
(g447
S'\xcf\xbb<\x1b\x9d\xf6\xee?'
tRp1640
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x11\x11\x11\x11\x11\x11\xa1?'
tRp1641
sg41
F896.70573902130127
sS'.minVal'
p1642
F0.050000000000000003
sS'.maxVal'
p1643
g340
sg38
S'up'
p1644
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I15
sg34
I1
sS'.stepType'
p1645
g344
sg52
g53
sg39
Vmop
p1646
sS'.staircase'
p1647
g350
sS'.nUp'
p1648
I1
sg26
I8
sg48
g49
sS'.condition'
p1649
g359
sg30
F0.25118864315095796
sS'.label'
p1650
g354
sg37
S'pop'
p1651
sS'.nDown'
p1652
I1
sa(dp1653
S'.stepSizes'
p1654
I4
sS'.startVal'
p1655
F1
sg28
g296
sg40
I00
sg32
g99
(g447
S'\x9d\xed\xf7\xe5\x98\xe0\x05@'
tRp1656
sg29
I4
sg50
g51
sg31
g99
(g447
S'ffffff\xf6?'
tRp1657
sg41
F908.4335560798645
sS'.minVal'
p1658
F0.050000000000000003
sS'.maxVal'
p1659
g340
sg38
S'down'
p1660
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I16
sg34
I1
sS'.stepType'
p1661
g344
sg52
g53
sg39
Vbraid
p1662
sS'.staircase'
p1663
g350
sS'.nUp'
p1664
I1
sg26
I9
sg48
g49
sS'.condition'
p1665
g359
sg30
F0.3981071705534972
sS'.label'
p1666
g354
sg37
S'grade'
p1667
sS'.nDown'
p1668
I1
sa(dp1669
S'.stepSizes'
p1670
I4
sS'.startVal'
p1671
F1
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xb8\xe3\xb6\xb9t\x13\x03@'
tRp1672
sg29
I4
sg50
g51
sg31
g99
(g447
S'wwwwww\xf3?'
tRp1673
sg41
F918.92121911048889
sS'.minVal'
p1674
F0.050000000000000003
sS'.maxVal'
p1675
g309
sg38
S'down'
p1676
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I17
sg34
I1
sS'.stepType'
p1677
g317
sg52
g53
sg39
Vbest
p1678
sS'.staircase'
p1679
g323
sS'.nUp'
p1680
I3
sg26
I9
sg48
g49
sS'.condition'
p1681
g332
sg30
F0.25118864315095796
sS'.label'
p1682
g327
sg37
S'best'
p1683
sS'.nDown'
p1684
I1
sa(dp1685
S'.stepSizes'
p1686
I4
sS'.startVal'
p1687
F1
sg28
g296
sg40
I01
sg32
g99
(g447
S'i\x85\xc8\xf87\x02\x00@'
tRp1688
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xed?'
tRp1689
sg41
F928.77705407142639
sS'.minVal'
p1690
F0.050000000000000003
sS'.maxVal'
p1691
g340
sg38
S'down'
p1692
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I18
sg34
I1
sS'.stepType'
p1693
g344
sg52
g53
sg39
Vset
p1694
sS'.staircase'
p1695
g350
sS'.nUp'
p1696
I1
sg26
I10
sg48
g49
sS'.condition'
p1697
g359
sg30
F0.63095734448019325
sS'.label'
p1698
g354
sg37
S'set'
p1699
sS'.nDown'
p1700
I1
sa(dp1701
S'.stepSizes'
p1702
I4
sS'.startVal'
p1703
F1
sg28
g128
sg40
I01
sg32
g99
(g447
S'8q\xf7W\xd6j\xfe?'
tRp1704
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xab\xaa\xaa\xaa\xaa\xaa\xea?'
tRp1705
sg41
F938.45687913894653
sS'.minVal'
p1706
F0.050000000000000003
sS'.maxVal'
p1707
g309
sg38
S'left'
p1708
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I19
sg34
I1
sS'.stepType'
p1709
g317
sg52
g53
sg39
Vpen
p1710
sS'.staircase'
p1711
g323
sS'.nUp'
p1712
I3
sg26
I10
sg48
g49
sS'.condition'
p1713
g332
sg30
F0.15848931924611132
sS'.label'
p1714
g327
sg37
S'pen'
p1715
sS'.nDown'
p1716
I1
sa(dp1717
S'.stepSizes'
p1718
I4
sS'.startVal'
p1719
F2.004748934509089
sg28
g446
sg40
I00
sg32
g99
(g447
S'f\x12\xeb\xbf\x1eE\xf4?'
tRp1720
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x11\x11\x11\x11\x11\x11\xd1?'
tRp1721
sg41
F951.0487949848175
sS'.minVal'
p1722
F0.050000000000000003
sS'.maxVal'
p1723
g373
sg38
S'left'
p1724
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I0
sg34
I1
sS'.stepType'
p1725
g379
sg52
g53
sg39
Vbongo drums
p1726
sS'.staircase'
p1727
g385
sS'.nUp'
p1728
I3
sg26
I1
sg48
g49
sS'.condition'
p1729
g394
sg30
F4
sS'.label'
p1730
g389
sg37
S'water running'
p1731
sS'.nDown'
p1732
I1
sa(dp1733
S'.stepSizes'
p1734
I4
sS'.startVal'
p1735
F1.2649110640673515
sg28
g446
sg40
I01
sg32
g99
(g447
S'\xacw"\x83\xcf@\x00@'
tRp1736
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x88\x88\x88\x88\x88\x88\xf0?'
tRp1737
sg41
F960.76851105690002
sS'.minVal'
p1738
F0.050000000000000003
sS'.maxVal'
p1739
g402
sg38
S'left'
p1740
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I1
sg34
I1
sS'.stepType'
p1741
g406
sg52
g53
sg39
Vtropical bird
p1742
sS'.staircase'
p1743
g412
sS'.nUp'
p1744
I1
sg26
I1
sg48
g49
sS'.condition'
p1745
g421
sg30
F4
sS'.label'
p1746
g416
sg37
S'tropical bird'
p1747
sS'.nDown'
p1748
I1
sa(dp1749
S'.stepSizes'
p1750
I4
sS'.startVal'
p1751
F2.004748934509089
sg28
g296
sg40
I01
sg32
g99
(g447
S'\xfa\xa48\x01\x00 \xf2?'
tRp1752
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xdd?'
tRp1753
sg41
F970.92037391662598
sS'.minVal'
p1754
F0.050000000000000003
sS'.maxVal'
p1755
g373
sg38
S'up'
p1756
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I2
sg34
I1
sS'.stepType'
p1757
g379
sg52
g53
sg39
Vwhip crack
p1758
sS'.staircase'
p1759
g385
sS'.nUp'
p1760
I3
sg26
I2
sg48
g49
sS'.condition'
p1761
g394
sg30
F6.3395727698444544
sS'.label'
p1762
g389
sg37
S'whip crack'
p1763
sS'.nDown'
p1764
I1
sa(dp1765
S'.stepSizes'
p1766
I4
sS'.startVal'
p1767
F1.2649110640673515
sg28
g128
sg40
I00
sg32
g99
(g447
S'\x87\xca>13\xb3\x07@'
tRp1768
sg29
I4
sg50
g51
sg31
g99
(g447
S'""""""\x00@'
tRp1769
sg41
F980.99219012260437
sS'.minVal'
p1770
F0.050000000000000003
sS'.maxVal'
p1771
g402
sg38
S'right'
p1772
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I3
sg34
I1
sS'.stepType'
p1773
g406
sg52
g53
sg39
Vkeyboard typing
p1774
sS'.staircase'
p1775
g412
sS'.nUp'
p1776
I1
sg26
I2
sg48
g49
sS'.condition'
p1777
g421
sg30
F2.523829377920773
sS'.label'
p1778
g416
sg37
S'helicopter'
p1779
sS'.nDown'
p1780
I1
sa(dp1781
S'.stepSizes'
p1782
I4
sS'.startVal'
p1783
F1.2649110640673515
sg28
g296
sg40
I01
sg32
g99
(g447
S'\xfdyR\xe8\x89j\x04@'
tRp1784
sg29
I4
sg50
g51
sg31
g99
(g447
S'""""""\xfe?'
tRp1785
sg41
F990.32803297042847
sS'.minVal'
p1786
F0.050000000000000003
sS'.maxVal'
p1787
g402
sg38
S'up'
p1788
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I4
sg34
I1
sS'.stepType'
p1789
g406
sg52
g53
sg39
Vice in a glass
p1790
sS'.staircase'
p1791
g412
sS'.nUp'
p1792
I1
sg26
I3
sg48
g49
sS'.condition'
p1793
g421
sg30
F4
sS'.label'
p1794
g416
sg37
S'ice in a glass'
p1795
sS'.nDown'
p1796
I1
sa(dp1797
S'.stepSizes'
p1798
I4
sS'.startVal'
p1799
F2.004748934509089
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xbf\xe8\xbf\x88\xb3O\xff?'
tRp1800
sg29
I4
sg50
g51
sg31
g99
(g447
S'DDDDDD\xf0?'
tRp1801
sg41
F1001.5758559703827
sS'.minVal'
p1802
F0.050000000000000003
sS'.maxVal'
p1803
g373
sg38
S'right'
p1804
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I5
sg34
I1
sS'.stepType'
p1805
g379
sg52
g53
sg39
Vrock splashing into water
p1806
sS'.staircase'
p1807
g385
sS'.nUp'
p1808
I3
sg26
I3
sg48
g49
sS'.condition'
p1809
g394
sg30
F4
sS'.label'
p1810
g389
sg37
S'rock splashing into water'
p1811
sS'.nDown'
p1812
I1
sa(dp1813
S'.stepSizes'
p1814
I4
sS'.startVal'
p1815
F2.004748934509089
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xf5\x15TT\xff\xc6\xf8?'
tRp1816
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xcd\xcc\xcc\xcc\xcc\xcc\xe4?'
tRp1817
sg41
F1011.7997369766235
sS'.minVal'
p1818
F0.050000000000000003
sS'.maxVal'
p1819
g373
sg38
S'right'
p1820
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I6
sg34
I1
sS'.stepType'
p1821
g379
sg52
g53
sg39
Velephant
p1822
sS'.staircase'
p1823
g385
sS'.nUp'
p1824
I3
sg26
I4
sg48
g49
sS'.condition'
p1825
g394
sg30
F2.523829377920773
sS'.label'
p1826
g389
sg37
S'elephant'
p1827
sS'.nDown'
p1828
I1
sa(dp1829
S'.stepSizes'
p1830
I4
sS'.startVal'
p1831
F1.2649110640673515
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xf2\xfdvc;\x7f\xf0?'
tRp1832
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xab\xaa\xaa\xaa\xaa\xaa\xda?'
tRp1833
sg41
F1020.8075489997864
sS'.minVal'
p1834
F0.050000000000000003
sS'.maxVal'
p1835
g402
sg38
S'up'
p1836
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I7
sg34
I1
sS'.stepType'
p1837
g406
sg52
g53
sg39
Vbird chirping
p1838
sS'.staircase'
p1839
g412
sS'.nUp'
p1840
I1
sg26
I4
sg48
g49
sS'.condition'
p1841
g421
sg30
F2.523829377920773
sS'.label'
p1842
g416
sg37
S'bird chirping'
p1843
sS'.nDown'
p1844
I1
sa(dp1845
S'.stepSizes'
p1846
I4
sS'.startVal'
p1847
F2.004748934509089
sg28
g128
sg40
I00
sg32
g99
(g447
S'$"\xfc\x13K\x9e\x04@'
tRp1848
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xdd\xdd\xdd\xdd\xdd\xdd\xfd?'
tRp1849
sg41
F1032.1434071063995
sS'.minVal'
p1850
F0.050000000000000003
sS'.maxVal'
p1851
g373
sg38
S'right'
p1852
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I8
sg34
I1
sS'.stepType'
p1853
g379
sg52
g53
sg39
Vcat
p1854
sS'.staircase'
p1855
g385
sS'.nUp'
p1856
I3
sg26
I5
sg48
g49
sS'.condition'
p1857
g394
sg30
F1.5924286822139888
sS'.label'
p1858
g389
sg37
S'toilet flushing'
p1859
sS'.nDown'
p1860
I1
sa(dp1861
S'.stepSizes'
p1862
I4
sS'.startVal'
p1863
F1.2649110640673515
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xb7\xea\xffyh1\xf0?'
tRp1864
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x9a\x99\x99\x99\x99\x99\xa9?'
tRp1865
sg41
F1042.2951250076294
sS'.minVal'
p1866
F0.050000000000000003
sS'.maxVal'
p1867
g402
sg38
S'down'
p1868
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I9
sg34
I1
sS'.stepType'
p1869
g406
sg52
g53
sg39
Vcow
p1870
sS'.staircase'
p1871
g412
sS'.nUp'
p1872
I1
sg26
I5
sg48
g49
sS'.condition'
p1873
g421
sg30
F1.5924286822139888
sS'.label'
p1874
g416
sg37
S'cow'
p1875
sS'.nDown'
p1876
I1
sa(dp1877
S'.stepSizes'
p1878
I4
sS'.startVal'
p1879
F2.004748934509089
sg28
g128
sg40
I00
sg32
g99
(g447
S'8\xc4Y\xbc\xf5\xe8\x01@'
tRp1880
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xf4?'
tRp1881
sg41
F1052.7669711112976
sS'.minVal'
p1882
F0.050000000000000003
sS'.maxVal'
p1883
g373
sg38
S'down'
p1884
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I10
sg34
I1
sS'.stepType'
p1885
g379
sg52
g53
sg39
Vhelicopter
p1886
sS'.staircase'
p1887
g385
sS'.nUp'
p1888
I3
sg26
I6
sg48
g49
sS'.condition'
p1889
g394
sg30
F1.5924286822139888
sS'.label'
p1890
g389
sg37
S'bowling'
p1891
sS'.nDown'
p1892
I1
sa(dp1893
S'.stepSizes'
p1894
I4
sS'.startVal'
p1895
F1.2649110640673515
sg28
g128
sg40
I00
sg32
g99
(g447
S'0\xb2\x14\x91\x8a\x13\x04@'
tRp1896
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xfc?'
tRp1897
sg41
F1062.8147749900818
sS'.minVal'
p1898
F0.050000000000000003
sS'.maxVal'
p1899
g402
sg38
S'right'
p1900
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I11
sg34
I1
sS'.stepType'
p1901
g406
sg52
g53
sg39
Vhelicopter
p1902
sS'.staircase'
p1903
g412
sS'.nUp'
p1904
I1
sg26
I6
sg48
g49
sS'.condition'
p1905
g421
sg30
F1.0047545726038318
sS'.label'
p1906
g416
sg37
S'drums'
p1907
sS'.nDown'
p1908
I1
sa(dp1909
S'.stepSizes'
p1910
I4
sS'.startVal'
p1911
F2.004748934509089
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xfc\x015\xae\x00\xa9\x05@'
tRp1912
sg29
I4
sg50
g51
sg31
g99
(g447
S'ffffff\x00@'
tRp1913
sg41
F1074.8625791072845
sS'.minVal'
p1914
F0.050000000000000003
sS'.maxVal'
p1915
g373
sg38
S'right'
p1916
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I12
sg34
I1
sS'.stepType'
p1917
g379
sg52
g53
sg39
Vfrog
p1918
sS'.staircase'
p1919
g385
sS'.nUp'
p1920
I3
sg26
I7
sg48
g49
sS'.condition'
p1921
g394
sg30
F1.5924286822139888
sS'.label'
p1922
g389
sg37
S'frog'
p1923
sS'.nDown'
p1924
I1
sa(dp1925
S'.stepSizes'
p1926
I4
sS'.startVal'
p1927
F1.2649110640673515
sg28
g296
sg40
I01
sg32
g99
(g447
S'nb\nu0\xff\x05@'
tRp1928
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x00\x00\x00\x00\x00\x00\xfc?'
tRp1929
sg41
F1086.5105180740356
sS'.minVal'
p1930
F0.050000000000000003
sS'.maxVal'
p1931
g402
sg38
S'up'
p1932
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I13
sg34
I1
sS'.stepType'
p1933
g406
sg52
g53
sg39
Vmicrowave
p1934
sS'.staircase'
p1935
g412
sS'.nUp'
p1936
I1
sg26
I7
sg48
g49
sS'.condition'
p1937
g421
sg30
F1.5924286822139888
sS'.label'
p1938
g416
sg37
S'microwave'
p1939
sS'.nDown'
p1940
I1
sa(dp1941
S'.stepSizes'
p1942
I4
sS'.startVal'
p1943
F2.004748934509089
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xf6\xe5\xde\xa5\x9b\xf4\x01@'
tRp1944
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xef\xee\xee\xee\xee\xee\xf6?'
tRp1945
sg41
F1097.0303909778595
sS'.minVal'
p1946
F0.050000000000000003
sS'.maxVal'
p1947
g373
sg38
S'left'
p1948
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I14
sg34
I1
sS'.stepType'
p1949
g379
sg52
g53
sg39
Vbell
p1950
sS'.staircase'
p1951
g385
sS'.nUp'
p1952
I3
sg26
I8
sg48
g49
sS'.condition'
p1953
g394
sg30
F1.0047545726038318
sS'.label'
p1954
g389
sg37
S'bell'
p1955
sS'.nDown'
p1956
I1
sa(dp1957
S'.stepSizes'
p1958
I4
sS'.startVal'
p1959
F1.2649110640673515
sg28
g128
sg40
I01
sg32
g99
(g447
S'\xf2\x9e\xd3a\xc9\xcf\x04@'
tRp1960
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x99\x99\x99\x99\x99\x99\xf9?'
tRp1961
sg41
F1106.326110124588
sS'.minVal'
p1962
F0.050000000000000003
sS'.maxVal'
p1963
g402
sg38
S'down'
p1964
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I15
sg34
I1
sS'.stepType'
p1965
g406
sg52
g53
sg39
Vtambourine
p1966
sS'.staircase'
p1967
g412
sS'.nUp'
p1968
I1
sg26
I8
sg48
g49
sS'.condition'
p1969
g421
sg30
F1.0047545726038318
sS'.label'
p1970
g416
sg37
S'tambourine'
p1971
sS'.nDown'
p1972
I1
sa(dp1973
S'.stepSizes'
p1974
I4
sS'.startVal'
p1975
F1.2649110640673515
sg28
g128
sg40
I00
sg32
g99
(g447
S'\x04\xaa\xa0\x10go\x03@'
tRp1976
sg29
I4
sg50
g51
sg31
g99
(g447
S'\xef\xee\xee\xee\xee\xee\xf6?'
tRp1977
sg41
F1116.5899310112
sS'.minVal'
p1978
F0.050000000000000003
sS'.maxVal'
p1979
g402
sg38
S'left'
p1980
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I16
sg34
I1
sS'.stepType'
p1981
g406
sg52
g53
sg39
Vbike horn
p1982
sS'.staircase'
p1983
g412
sS'.nUp'
p1984
I1
sg26
I9
sg48
g49
sS'.condition'
p1985
g421
sg30
F0.63395727698444526
sS'.label'
p1986
g416
sg37
S'door creaking'
p1987
sS'.nDown'
p1988
I1
sa(dp1989
S'.stepSizes'
p1990
I4
sS'.startVal'
p1991
F2.004748934509089
sg28
g128
sg40
I00
sg32
g99
(g447
S'\xde\xdd\xdd\xdd\xdd\xdd\xf5?'
tRp1992
sg29
I4
sg50
g51
sg31
g99
(g447
S'wwwwww\xd7?'
tRp1993
sg41
F1126.7096700668335
sS'.minVal'
p1994
F0.050000000000000003
sS'.maxVal'
p1995
g373
sg38
S'up'
p1996
sg33
I1
sg35
I1
sg25
I0
sg36
I1
sg42
I00
sg60
g61
sg54
g55
sg46
g47
sg27
I17
sg34
I1
sS'.stepType'
p1997
g379
sg52
g53
sg39
Vwater bubbling
p1998
sS'.staircase'
p1999
g385
sS'.nUp'
p2000
I3
sg26
I9
sg48
g49
sS'.condition'
p2001
g394
sg30
F0.63395727698444526
sS'.label'
p2002
g389
sg37
S'sheep'
p2003
sS'.nDown'
p2004
I1
sa(dp2005
S'.stepSizes'
p2006
I4
sS'.startVal'
p2007
F1.2649110640673515
sg28
g296
sg40
I01
sg32
g99
(g447
S'iff`ff\xf2?'
tRp2008
sg29
I4
sg50
g51
sg31
g99
(g447
S'\x99\x99\x99\x99\x99\x99\xd9?'
tRp2009
sg41
F1136.9415409564972
sS'.minVal'
p2010
F0.050000000000000003
sS'.maxVal'
p2011
g402
sg38
S'right'
p2012
sg33
I1
sg35
I1
sg25
I1
sg36
I1
sg42
I01
sg60
g61
sg54
g55
sg46
g47
sg27
I18
sg34
I1
sS'.stepType'
p2013
g406
sg52
g53
sg39
Vwater dripping
p2014
sS'.staircase'
p2015
g412
sS'.nUp'
p2016
I1
sg26
I10
sg48
g49
sS'.condition'
p2017
g421
sg30
F1.0047545726038318
sS'.label'
p2018
g416
sg37
S'water dripping'
p2019
sS'.nDown'
p2020
I1
sasS'loops'
p2021
(lp2022
g65
ag172
ag236
ag301
ag65
ag172
ag236
ag301
ag365
asS'savePickle'
p2023
I00
sb.